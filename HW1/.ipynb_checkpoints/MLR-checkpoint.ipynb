{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
<<<<<<< HEAD
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function x"
=======
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(\"optim\")\n",
    "require('hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multinomial Logistic Regression - LBFGS Minibatch - L2 Norm</h3>"
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1[\"one\"] = 1"
=======
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neval = 0\n",
    "\n",
    "function ml(W, X, Y)\n",
    "    local W = W:reshape(Y:size(2), X:size(2)+1)\n",
    "    \n",
    "    --intercept\n",
    "    local b = W:sub(1, W:size(1), W:size(2),W:size(2)):t()\n",
    "    \n",
    "    --coefficient\n",
    "    W = W:sub(1, W:size(1),1,W:size(2)-1)\n",
    "    \n",
    "    --XW^T\n",
    "    local p = X*W:t()\n",
    "    \n",
    "    --XW^T + b\n",
    "    p:add(b:expand(b,p:size(1),b:size(2)))\n",
    "    \n",
    "    local arr = p:clone()\n",
    "    arr = arr:t()\n",
    "    \n",
    "    --predicted Z scores for y_hat\n",
    "    local vmax = arr:max(1)\n",
    "\n",
    "    local evmax = torch.expand(vmax,arr:size(1),vmax:size(2))\n",
    "\n",
    "    arr:csub(evmax)\n",
    "\n",
    "    arr:exp()\n",
    "    arr = arr:sum(1)\n",
    "    arr:log()\n",
    "    \n",
    "    arr:add(vmax)\n",
    "\n",
    "    arr = arr:t()\n",
    "    arr:expand(arr, arr:size(1), p:size(2))\n",
    "    p:csub(arr)\n",
    "    \n",
    "    --L2 regularization\n",
    "    local norm = W:reshape(W:size(1)*W:size(2), 1)\n",
    "    \n",
    "    local loss = (torch.sum(torch.cmul(Y,p))*-1) + 0.5 *1 * torch.dot(norm, norm)\n",
    "    \n",
    "    p:exp()\n",
    "    \n",
    "    return loss, p, W\n",
    "end\n",
    "\n",
    "function mlg(W, X, Y, bsize)\n",
    "\n",
    "    local bsize = 100\n",
    "    \n",
    "    --random ordering of ints [1,nexamples] and take first bsize\n",
    "    local idx = torch.randperm(X:size(1)):sub(1,bsize)\n",
    "    \n",
    "    --training minibatches\n",
    "    local X_batch = torch.Tensor(bsize, X:size(2))\n",
    "    local Y_batch = torch.Tensor(bsize, Y:size(2))\n",
    "    \n",
    "    for i=1,bsize do\n",
    "        X_batch[i] = X[idx[i]]\n",
    "        Y_batch[i] = Y[idx[i]]\n",
    "    end\n",
    "\n",
    "    --initialize gradient\n",
    "    local grad = torch.zeros(Y_batch:size(2), X_batch:size(1)+1)\n",
    "    \n",
    "    --calculate loss, updated weight matrix\n",
    "    local loss, p, W = ml(W, X_batch, Y_batch)\n",
    "\n",
    "    local diff = torch.csub(p,Y_batch)\n",
    "    \n",
    "    local grad = diff:t()*X_batch\n",
    "    grad:mul(0.1)\n",
    "    W:csub(grad)\n",
    "    W = W:cat(torch.zeros(grad:size(1),1), 2)\n",
    "    W:sub(1, W:size(1), W:size(2), W:size(2)):add(diff:sum(1))\n",
    "    print(loss)\n",
    "    return W:reshape(W:size(1)*W:size(2), 1)\n",
    "    --[[\n",
    "    grad:add(W)\n",
    "    grad = grad:cat(torch.zeros(grad:size(1),1), 2)\n",
    "    grad:sub(1, grad:size(1), grad:size(2), grad:size(2)):add(diff:sum(1))\n",
    "    neval = neval + 1\n",
    "    print(neval, loss)\n",
    "    return loss, grad:reshape(grad:size(1)*grad:size(2), 1)\n",
    "    ]]\n",
    "end\n",
    "\n",
    "\n",
    "function fit(X, Y, rate, iter, lX)\n",
    "    --Weight matrix must be passed in as vector\n",
    "    local W = torch.zeros(Y:size(2) * (X:size(2)+1), 1)   \n",
    "    \n",
    "    for i=1,iter do\n",
    "        W = mlg(W, X, Y)\n",
    "    end\n",
    "\n",
    "    \n",
    "    W = W:reshape(Y:size(2), X:size(2)+1)\n",
    "    \n",
    "    --intercept\n",
    "    b = W:sub(1, W:size(1), W:size(2), W:size(2))\n",
    "    \n",
    "    --coefficients\n",
    "    W = W:sub(1, W:size(1), 1, W:size(2)-1)\n",
    "    \n",
    "    return W, b\n",
    "end\n",
    "\n",
    "function predict(X, W, b)\n",
    "    local b = b:t()\n",
    "    return (X*W:t()):add(b:expand(b, X:size(1), b:size(2)))\n",
    "end\n",
    "\n",
    "function predict_score(ypred, ytrue)\n",
    "    local c = 0\n",
    "    for i=1,ypred:size(1) do\n",
    "        if ypred[i][1] == ytrue[i][1] then\n",
    "            c = c + 1       \n",
    "        end\n",
    "    end\n",
    "    return c/ypred:size(1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Document Word Matrix and One Hot Encoding</h3>"
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function fit(X, Y)\n",
    "    local W = torch.zeros(3, 5)\n",
    "    W = W:reshape(W:size(1) * W:size(2), 1)\n",
    "    \n",
    "end\n",
    "        "
=======
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--feature weight: counts\n",
    "function createDocWordMatrix(vocab, max_sent_len, sparseMatrix)\n",
    "    docword = torch.zeros(sparseMatrix:size(1), vocab)\n",
    "    for i=1,sparseMatrix:size(1) do\n",
    "        for j=1, max_sent_len do\n",
    "            local idx = (sparseMatrix[i][j])\n",
    "            if idx ~= 0 then\n",
    "                docword[i][idx] = 1 + docword[i][idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return docword\n",
    "end\n",
    " \n",
    "function onehotencode(classes, target)\n",
    "    onehot = torch.zeros(target:size(1), classes)\n",
    "    for i=1,target:size(1) do\n",
    "        onehot[i][target[i]] = 1\n",
    "    end\n",
    "    return onehot\n",
    "end\n",
    "\n",
    "function write2file(fname, pred) \n",
    "    f = io.open(fname, \"w\")\n",
    "    f:write(\"ID,Category\\n\")\n",
    "    for i=1,pred:size(1) do\n",
    "        f:write(tostring(i) .. \",\" .. tostring(pred[i][1]) .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = hdf5.open(\"SST1.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "X_valid = f:read(\"valid_input\"):all()\n",
    "Y_valid = f:read(\"valid_output\"):all()\n",
    "--X_test = f:read(\"test_input\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "\n",
    "f:close()"
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 5,
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "W = torch.zeros(3, 5)\n",
    "W = W:reshape(W:size(1) * W:size(2), 1)"
=======
    "X_train =createDocWordMatrix(nfeatures, 53, X_train)\n",
    "Y_train = onehotencode(nclasses, Y_train)\n",
    "X_test = createDocWordMatrix(nfeatures, 53, X_valid)\n",
    "Y_test = onehotencode(nclasses, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.94379124341\t\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2407.189680111\t\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11102.176944225\t\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11321.724637017\t\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "11245.988105409\t\n",
       "0\t\n"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = os.time()\n",
    "W, b = fit(X_train, Y_train, 0.1, 2)\n",
    "end_time = os.time()\n",
    "print(end_time - start_time)"
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 52,
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 15x1]\n",
       "\n"
      ]
     },
     "execution_count": 14,
=======
       "0.35603996366939\t\n"
      ]
     },
     "execution_count": 52,
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "W"
=======
    "Y_pred = predict(X_test, W, b)\n",
    "_, Y_pred = torch.max(Y_pred, 2)\n",
    "_,Y_true = torch.max(Y_test, 2)\n",
    "acc_score = predict_score(Y_pred, Y_true)\n",
    "print(acc_score)"
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
=======
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write2file(\"MLR_8.csv\", Y_pred)"
   ]
>>>>>>> 88967a75e68cda1e47e87138f4240432ee873c97
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
