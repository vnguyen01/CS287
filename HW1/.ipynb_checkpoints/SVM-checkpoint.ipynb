{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--Austin's Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require('hdf5')\n",
    "require 'nn'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = hdf5.open(\"SST1.hdf5\", \"r\")\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "--X_valid = f:read(\"valid_input\"):all()\n",
    "--Y_valid = f:read(\"valid_output\"):all()\n",
    "--X_test = f:read(\"test_input\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--DOC BY WORD (vincent's stuff)\n",
    "--feature weight: counts\n",
    "function createDocWordMatrix(vocab, max_sent_len, sparseMatrix)\n",
    "    docword = torch.zeros(sparseMatrix:size(1), vocab)\n",
    "    for i=1,sparseMatrix:size(1) do\n",
    "        for j=1, max_sent_len do\n",
    "            local idx = (sparseMatrix[i][j])\n",
    "            if idx ~= 0 then\n",
    "                docword[i][idx] = 1 + docword[i][idx]\n",
    "            end\n",
    "        end        \n",
    "    end\n",
    "    return docword\n",
    "end\n",
    "\n",
    "function onehotencode(classes, target)\n",
    "    onehot = torch.zeros(target:size(1), classes)\n",
    "    for i=1,target:size(1) do\n",
    "        onehot[i][target[i]] = 1\n",
    "    end\n",
    "    return onehot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=createDocWordMatrix(nfeatures, 53, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function linear(b, W, x)\n",
    "    --weight matrix W (dout x din), bias b (dout x 1), input matrix x (din x n)\n",
    "    local B = b:clone()\n",
    "    local B = B:expand(B,B:size(1),x:size(1))\n",
    "    return ((W*x:t()):add(B))\n",
    "end\n",
    "    \n",
    "function second_max(Y_pred, Y_true)\n",
    "    --Y_pred is a nx5 tensor\n",
    "    local second_maxes = torch.zeros(Y_pred:size(1),1)\n",
    "    local indices = second_maxes:clone()\n",
    "    local Y_prime = Y_pred:clone()\n",
    "    for i = 1, Y_pred:size(1) do\n",
    "        Y_prime[i][Y_true[i]] = -100\n",
    "        second_maxes[i], indices[i] = torch.max(Y_prime[i],1)\n",
    "        if indices[i] == 1 then\n",
    "            print('hi')\n",
    "        end\n",
    "    end\n",
    "    return second_maxes, indices\n",
    "end\n",
    "\n",
    "function correct_val(Y_pred, Y_true)\n",
    "    return_val = torch.zeros(Y_true:size(1),1)\n",
    "    for i = 1, Y_true:size(1) do\n",
    "        return_val[i] = Y_pred[i][Y_true[i]]\n",
    "    end\n",
    "    return return_val\n",
    "end\n",
    "\n",
    "\n",
    "function hinge_grad(W,x,b,Y_true,lambda)\n",
    "    local Y_pred = linear(b,W,x):t()\n",
    "    local condition = torch.Tensor(Y_true:size(1),1)\n",
    "    local correct = correct_val(Y_pred,Y_true) \n",
    "    local second, s_indices = second_max(Y_pred,Y_true)\n",
    "    local condition = correct - second\n",
    "    local W_grad = torch.zeros(W:size())\n",
    "    local W_temp = torch.zeros(W:size())\n",
    "    local b_grad = torch.zeros(b:size())\n",
    "    local b_temp = torch.zeros(b:size())\n",
    "    for i = 1, condition:size(1) do\n",
    "        if condition[i][1] < 1 then\n",
    "            for j = 1, W:size(1) do\n",
    "                if j == Y_true[i] then\n",
    "                    b_temp[j] = -1\n",
    "                    W_temp[j] = x[i]*(-1)\n",
    "                elseif j == s_indices[i] then\n",
    "            \n",
    "                    b_temp[j] = 1\n",
    "                    W_temp[j] = x[i]\n",
    "                else\n",
    "                    b_temp[j] = 0\n",
    "                    W_temp[j] = W_temp[j]*0\n",
    "                end\n",
    "            end\n",
    "            b_grad:add(b_temp)\n",
    "            W_grad:add(W_temp)\n",
    "        end\n",
    "    end\n",
    "    return W_grad+2*lambda*torch.sum(W),b_grad+2*lambda*torch.sum(b_grad)\n",
    "end\n",
    "\n",
    "function hinge_loss(Y_pred, Y_true, W,lambda)\n",
    "    --Y_pred is a nx5 tensor, Y_true is an nx1 tensor\n",
    "    local ones_vector = torch.ones(Y_true:size(1),1)\n",
    "    local loss_vector = nn.ReLU():forward(ones_vector+second_max(Y_pred, Y_true)-correct_val(Y_pred,Y_true))\n",
    "    return loss_vector:sum(1) + lambda*torch.norm(W)\n",
    "    \n",
    "end\n",
    "\n",
    "function obj(params,x,y,lambda)\n",
    "    --bsize = 1000\n",
    "    --local idx = torch.randperm(X:size(1)):sub(1,bsize)\n",
    "    --local x = torch.Tensor(bsize, X:size(2))\n",
    "    --local y = torch.Tensor(bsize, 1)\n",
    "    --for i=1,bsize do\n",
    "    --   x[i] = X[idx[i]]\n",
    "    --    y[i] = Y[idx[i]]\n",
    "    --end\n",
    "    \n",
    "    --y = y:squeeze()\n",
    "\n",
    "    local w = params:sub(1,params:size(1),1,params:size(2)-1)\n",
    "   \n",
    "    b = params:sub(1,params:size(1),params:size(2),params:size(2))\n",
    "    local ypred = linear(b,w,x)\n",
    "    local sloss = hinge_loss(ypred:t(),y,w,lambda)\n",
    "    \n",
    "    local w1,b1 = hinge_grad(w,x,b,y,lambda)\n",
    "    local grads = torch.zeros(params:size())\n",
    "    grads[{{},{1,params:size(2)-1}}] = w1\n",
    "    grads[{{},{params:size(2),params:size(2)}}] = b\n",
    "    print(sloss)\n",
    "    return sloss, grads\n",
    "end\n",
    "\n",
    "\n",
    "function fit(X, Y)\n",
    "    local W0 = torch.zeros(3,X:size(2))\n",
    "    local b0 = torch.zeros(3,1)\n",
    "    local W = torch.cat(W0, b0, 2)\n",
    "    \n",
    "    local func = function(W)\n",
    "        loss, grads = obj(W, X, Y, 1)\n",
    "        return loss[1][1], grads\n",
    "    end\n",
    "    state = {learningRate=0.1, maxIter=10}\n",
    "    W, f_hist, currentFuncEval = optim.lbfgs(func, W, state)\n",
    "    \n",
    "    b = W:sub(1, W:size(1), W:size(2), W:size(2))\n",
    "    \n",
    "    --coefficients\n",
    "    W = W:sub(1, W:size(1), 1, W:size(2)-1)\n",
    "    \n",
    "    return W, b\n",
    "end\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 3.9112\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 3.7750\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 3.3221\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 2.1837\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 2.1503\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 2.1506\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 220.9183\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 195.9729\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n",
       " 355.3617\n",
       "[torch.DoubleTensor of size 1x1]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.Tensor{{1,0,0},{0,1,0},{0,0,1},{0,0,1}}\n",
    "Y_train = torch.Tensor{1,2,3, 3}\n",
    "W, b = fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    " --intercept\n",
    "b = p0:sub(1, p0:size(1), p0:size(2), p0:size(2))\n",
    "\n",
    "--coefficients\n",
    "W = p0:sub(1, p0:size(1), 1, p0:size(2)-1)\n",
    "\n",
    "X_valid=createDocWordMatrix(nfeatures, 53, X_valid)\n",
    "\n",
    "function predict(X, W, b)\n",
    "    local b = b:t()\n",
    "    return (X*W:t()):add(b:expand(b, X:size(1), b:size(2)))\n",
    "end\n",
    "function predict_score(ypred, ytrue)\n",
    "    local c = 0\n",
    "    for i=1,ypred:size(1) do\n",
    "        if ypred[i][1] == ytrue[i][1] then\n",
    "            c = c + 1       \n",
    "        end\n",
    "    end\n",
    "    return c/ypred:size(1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = predict(X_train, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0063322216341341\t\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, Y_pred = torch.max(Y_pred, 2)\n",
    "_,Y_true = torch.max(Y_train, 2)\n",
    "acc_score = predict_score(Y_pred, Y_train)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = Y_train:reshape(Y_train:size(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 156817\n",
       "      1\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"Y_train = Y_train:reshape(Y_train:size,)...\"]:1: function arguments expected near ','",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"Y_train = Y_train:reshape(Y_train:size,)...\"]:1: function arguments expected near ','"
     ]
    }
   ],
   "source": [
    "Y_train = Y_train:reshape(Y_train:size,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = Y_train:squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 156817\n",
       "[torch.LongStorage of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
