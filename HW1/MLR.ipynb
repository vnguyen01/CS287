{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(\"optim\")\n",
    "require('hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multinomial Logistic Regression - LBFGS Minibatch - L2 Norm</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function ml(W, X, Y)\n",
    "    local W = W:reshape(Y:size(2), X:size(2)+1)\n",
    "    local b = W:sub(1, W:size(1), W:size(2),W:size(2)):t()\n",
    "    W = W:sub(1, W:size(1),1,W:size(2)-1)\n",
    "    local p = X*W:t()\n",
    "    p:add(b:expand(b,p:size(1),b:size(2)))\n",
    "    local arr = p:clone()\n",
    "    arr = arr:t()\n",
    "    local vmax = arr:max(1)\n",
    "    local evmax = torch.expand(vmax,arr:size(1),vmax:size(2))\n",
    "    arr:csub(evmax)\n",
    "    arr:exp()\n",
    "    arr = arr:sum(1)\n",
    "    arr:log()\n",
    "    arr:add(vmax)\n",
    "    arr = arr:t()\n",
    "    arr:expand(arr, arr:size(1), p:size(2))\n",
    "    p:csub(arr)\n",
    "    --local norm = W:reshape(W:size(1)*W:size(2), 1)\n",
    "    local loss = (torch.sum(torch.cmul(Y,p))*-1) + 1.0 *0.5 * torch.norm(W) --torch.dot(norm, norm)\n",
    "    p:exp()\n",
    "    return loss, p, W\n",
    "end\n",
    "\n",
    "function mlg(W, X, Y)\n",
    "    local bsize = 5000\n",
    "    local idx = torch.randperm(X:size(1)):sub(1,bsize)\n",
    "    local X_batch = torch.Tensor(bsize, X:size(2))\n",
    "    local Y_batch = torch.Tensor(bsize, Y:size(2))\n",
    "    \n",
    "    for i=1,bsize do\n",
    "        X_batch[i] = X[idx[i]]\n",
    "        Y_batch[i] = Y[idx[i]]\n",
    "    end\n",
    "\n",
    "    local grad = torch.zeros(Y_batch:size(2), X_batch:size(1)+1)\n",
    "    local loss, p, W = ml(W, X_batch, Y_batch)\n",
    "    local diff = torch.csub(p,Y_batch)\n",
    " \n",
    "    local grad = diff:t()*X_batch\n",
    "\n",
    "    grad:add(W)\n",
    "    grad = grad:cat(torch.zeros(grad:size(1),1), 2)\n",
    "    grad:sub(1, grad:size(1), grad:size(2), grad:size(2)):add(diff:sum(1))\n",
    "    print(loss)\n",
    "    return loss, grad:reshape(grad:size(1)*grad:size(2), 1), p\n",
    "end\n",
    "\n",
    "\n",
    "function fit(X, Y, rate, iter, lX)\n",
    "\n",
    "    local W = torch.zeros(Y:size(2) * (X:size(2)+1), 1)    \n",
    "    local func = function(W)\n",
    "        loss, grad, p = mlg(W, X, Y)\n",
    "        return loss, grad\n",
    "    end\n",
    "    local state = {learningRate = rate, maxIter=iter, tolX=lX}\n",
    "    W, f_hist, currentFuncEval = optim.lbfgs(func, W, state)\n",
    "    W = W:reshape(Y:size(2), X:size(2)+1)\n",
    "    b = W:sub(1, W:size(1), W:size(2), W:size(2))\n",
    "    W = W:sub(1, W:size(1), 1, W:size(2)-1)\n",
    "    return W, b\n",
    "end\n",
    "\n",
    "function predict(X, W, b)\n",
    "    local b = b:t()\n",
    "    return (X*W:t()):add(b:expand(b, X:size(1), b:size(2)))\n",
    "end\n",
    "\n",
    "function predict_score(ypred, ytrue)\n",
    "    local c = 0\n",
    "    for i=1,ypred:size(1) do\n",
    "        if ypred[i][1] == ytrue[i][1] then\n",
    "            c = c + 1       \n",
    "        end\n",
    "    end\n",
    "    return c/ypred:size(1)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Document Word Matrix and One Hot Encoding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "--feature weight: counts\n",
    "function createDocWordMatrix(vocab, max_sent_len, sparseMatrix)\n",
    "    docword = torch.zeros(sparseMatrix:size(1), vocab)\n",
    "    for i=1,sparseMatrix:size(1) do\n",
    "        for j=1, max_sent_len do\n",
    "            local idx = (sparseMatrix[i][j])\n",
    "            if idx ~= 0 then\n",
    "                docword[i][idx] = 1 + docword[i][idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return docword\n",
    "end\n",
    " \n",
    "function onehotencode(classes, target)\n",
    "    onehot = torch.zeros(target:size(1), classes)\n",
    "    for i=1,target:size(1) do\n",
    "        onehot[i][target[i]] = 1\n",
    "    end\n",
    "    return onehot\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = hdf5.open(\"SST1.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "X_valid = f:read(\"valid_input\"):all()\n",
    "Y_valid = f:read(\"valid_output\"):all()\n",
    "X_test = f:read(\"test_input\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train =createDocWordMatrix(nfeatures, 53, X_train)\n",
    "Y_train = onehotencode(nclasses, Y_train)\n",
    "X_test = createDocWordMatrix(nfeatures, 53, X_valid)\n",
    "Y_test = onehotencode(nclasses, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"function ml(W, X, Y)...\"]:52: attempt to index local 'Y' (a nil value)\nstack traceback:\n\t[string \"function ml(W, X, Y)...\"]:52: in function 'fit'\n\t[string \"start_time = os.time()...\"]:2: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/Vincent/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010d97cbd0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"function ml(W, X, Y)...\"]:52: attempt to index local 'Y' (a nil value)\nstack traceback:\n\t[string \"function ml(W, X, Y)...\"]:52: in function 'fit'\n\t[string \"start_time = os.time()...\"]:2: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/Vincent/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010d97cbd0"
     ]
    }
   ],
   "source": [
    "start_time = os.time()\n",
    "W, b = fit(X_train, Y_train, 0.1, 100)\n",
    "end_time = os.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34241598546776\t\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = predict(X_test, W, b)\n",
    "_, Y_pred = torch.max(Y_pred, 2)\n",
    "_,Y_true = torch.max(Y_test, 2)\n",
    "acc_score = predict_score(Y_pred, Y_true)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
