{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--SVM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('hdf5')\n",
    "require 'nn'\n",
    "require 'optim'\n",
    "require 'math'\n",
    "\n",
    "f = hdf5.open(\"SST2.hdf5\", \"r\")\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "X_valid = f:read(\"valid_input\"):all()\n",
    "Y_valid = f:read(\"valid_output\"):all()\n",
    "--X_test = f:read(\"test_input\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--DOC BY WORD (vincent's stuff)\n",
    "--feature weight: counts\n",
    "function createDocWordMatrix(vocab, max_sent_len, sparseMatrix)\n",
    "    docword = torch.zeros(sparseMatrix:size(1), vocab)\n",
    "    for i=1,sparseMatrix:size(1) do\n",
    "        for j=1, max_sent_len do\n",
    "            local idx = (sparseMatrix[i][j])\n",
    "            if idx ~= 0 then\n",
    "                docword[i][idx] = 1 --+ docword[i][idx]\n",
    "            end\n",
    "        end        \n",
    "    end\n",
    "    return docword\n",
    "end\n",
    "\n",
    "function onehotencode(classes, target)\n",
    "    onehot = torch.zeros(target:size(1), classes)\n",
    "    for i=1,target:size(1) do\n",
    "        onehot[i][target[i]] = 1\n",
    "    end\n",
    "    return onehot\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function isnan(m)\n",
    "    if m ~= m then\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end\n",
    "\n",
    "function linear(b, W, x)\n",
    "    --weight matrix W (dout x din), bias b (dout x 1), input matrix x (n x din)\n",
    "    local B = b:clone()\n",
    "    local B = B:expand(B,B:size(1),x:size(1))\n",
    "    return ((W*x:t()):add(B)):t()\n",
    "end\n",
    "    \n",
    "function second_max(Y_pred, Y_true)\n",
    "    --Y_pred is a nx5 tensor\n",
    "    local second_maxes = torch.zeros(Y_pred:size(1),1)\n",
    "    local indices = second_maxes:clone()\n",
    "    local Y_prime = (Y_pred):clone()\n",
    "    for i = 1, Y_pred:size(1) do\n",
    "        Y_prime[i][Y_true[i]] = -100\n",
    "        z1,z2 = torch.max(Y_prime[i],1)\n",
    "        second_maxes[i] = z1[1]\n",
    "        indices[i] = z2[1]\n",
    "    end\n",
    "    return second_maxes, indices\n",
    "end\n",
    "\n",
    "function correct_val(Y_pred, Y_true)\n",
    "    return_val = torch.zeros(Y_true:size(1),1)\n",
    "    for i = 1, Y_true:size(1) do\n",
    "        return_val[i] = Y_pred[i][Y_true[i]]\n",
    "    end\n",
    "    return return_val\n",
    "end\n",
    "\n",
    "function ReLU(input)\n",
    "    for i = 1,input:size(1) do\n",
    "        if input[i][1]<0 then\n",
    "            input[i][1] =0\n",
    "        end\n",
    "    end\n",
    "    return input\n",
    "end\n",
    "\n",
    "function hinge_loss(Y_pred, Y_true, W,lambda,b, mode)\n",
    "    --Y_pred is a nx5 tensor, Y_true is an nx1 tensor\n",
    "    --mode = 'vanilla' for vanilla hinge\n",
    "    --mode = 'L2' for hinge^2\n",
    "    if mode == 'vanilla' then\n",
    "        reg = 1\n",
    "    elseif mode == 'squared' then\n",
    "        reg = 2\n",
    "    end\n",
    "    \n",
    "    params = torch.cat(W,b,2)\n",
    "    local ones_vector = torch.ones(Y_true:size(1),1)\n",
    "    local loss_vector = torch.pow(ReLU(ones_vector+second_max(Y_pred, Y_true)-correct_val(Y_pred,Y_true)),reg)\n",
    "    loss1 = lambda*torch.pow((torch.norm(params)),2)\n",
    "    loss2 = loss_vector:sum(1)[1][1]\n",
    "    \n",
    "    return (loss1 + loss2)\n",
    "end\n",
    "\n",
    "function hinge_grad(W,x,b,Y_true,lambda, mode)\n",
    "    local Y_pred = linear(b,W,x)\n",
    "    local loss = hinge_loss(Y_pred, Y_true, W, lambda, b, mode)\n",
    "    local condition = torch.Tensor(Y_true:size(1),1)\n",
    "    local correct = correct_val(Y_pred,Y_true) \n",
    "    local second, s_indices = second_max(Y_pred,Y_true)\n",
    "    local condition = correct - second\n",
    "    local W_grad = torch.zeros(W:size())\n",
    "    local W_temp = torch.zeros(W:size())\n",
    "    local b_grad = torch.zeros(b:size())\n",
    "    local b_temp = torch.zeros(b:size())\n",
    "    local debug = torch.zeros(4)\n",
    "    for i = 1, condition:size(1) do\n",
    "        if condition[i][1] < 1 then\n",
    "            for j = 1, W:size(1) do\n",
    "                if j == Y_true[i] then\n",
    "                    b_temp[j] = -1\n",
    "                    W_temp[j] = x[i]*(-1)*loss\n",
    "                    debug[1] = debug[1] + 1\n",
    "                elseif j == s_indices[i][1] then\n",
    "                    debug[2] = debug[2] + 1\n",
    "                    b_temp[j] = 1\n",
    "                    W_temp[j] = x[i]*loss\n",
    "                else\n",
    "                    debug[3] = debug[3] + 1\n",
    "                    b_temp[j] = 0\n",
    "                    W_temp[j] = W_temp[j]*0\n",
    "                end\n",
    "            end\n",
    "            b_grad:add(b_temp)\n",
    "            W_grad:add(W_temp)\n",
    "        else\n",
    "            debug[4] = debug[4] + 1\n",
    "            b_temp = torch.zeros(b_temp:size())\n",
    "            W_temp = torch.zeros(W_temp:size())\n",
    "        end\n",
    "    end\n",
    "    return W_grad:add(2*lambda,W),b_grad:add(2*lambda,b)\n",
    "    --return W_grad,0--b_grad\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function obj(params,X,Y,batch,lambda, mode)\n",
    "    if batch > 0 then\n",
    "        bsize= batch\n",
    "        local idx = torch.randperm(X:size(1)):sub(1,bsize)\n",
    "\n",
    "        x = torch.Tensor(bsize, X:size(2))\n",
    "\n",
    "        Y = Y:reshape(Y:size(1), 1)\n",
    "\n",
    "        y = torch.Tensor(bsize, 1)\n",
    "\n",
    "        for i=1,bsize do\n",
    "            x[i] = X[idx[i]]\n",
    "            y[i] = Y[idx[i]]\n",
    "        end\n",
    "        \n",
    "        y = y:squeeze()\n",
    "    else\n",
    "        y = Y\n",
    "        x = X\n",
    "    end\n",
    "    \n",
    "    local w = (params:sub(1,params:size(1),1,params:size(2)-1))\n",
    "    \n",
    "   \n",
    "    b = params:sub(1,params:size(1),params:size(2),params:size(2))\n",
    "    local ypred = linear(b,w,x)\n",
    "    local loss = hinge_loss(ypred,y,w,lambda,b, mode)\n",
    "    \n",
    "    local w1,b1 = hinge_grad(w,x,b,y,lambda, mode)\n",
    "    local grads = torch.zeros(params:size())\n",
    "    grads[{{},{1,params:size(2)-1}}] = w1\n",
    "    grads[{{},{params:size(2),params:size(2)}}] = b1\n",
    "    return loss, grads\n",
    "end\n",
    "\n",
    "function obj_final(params)\n",
    "    \n",
    "    loss,grads = obj(params, X_train, Y_train, 50, 1, 'vanilla')\n",
    "    print(loss)\n",
    "    return loss,grads\n",
    "end\n",
    "\n",
    "--params\n",
    "local lr = rate\n",
    "local b1 = 0.9\n",
    "local b2 = 0.999\n",
    "local e = 1e-8\n",
    "local t = 0\n",
    "local m\n",
    "local v\n",
    "local denom\n",
    "\n",
    "function adam(W)\n",
    "    --quicker and smoother than sgd\n",
    "    --https://github.com/torch/optim/blob/master/adam.lua\n",
    "    --http://arxiv.org/pdf/1412.6980.pdf\n",
    "    local _,grad = obj_final(W)\n",
    "    m = m or W.new(grad:size()):zero()\n",
    "    v = v or W.new(grad:size()):zero()\n",
    "    denom = denom or W.new(grad:size()):zero()\n",
    "    t = t + 1\n",
    "    m:mul(b1):add(1-b1, grad)\n",
    "    v:mul(b2):addcmul(1-b2, grad, grad)\n",
    "    denom:copy(v):sqrt():add(e)\n",
    "    local biasCorrection1 = 1 - b1^t\n",
    "    local biasCorrection2 = 1 - b2^t\n",
    "    local stepSize = lr * math.sqrt(biasCorrection2)/biasCorrection1\n",
    "    W:addcdiv(-stepSize, m, denom)\n",
    "    return W\n",
    "end\n",
    "\n",
    "function sgd(W)\n",
    "    local _, grad = obj_final(W)\n",
    "    grad:mul(lr)\n",
    "    W = W:csub(grad)\n",
    "    return W\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train=createDocWordMatrix(nfeatures, 53, X_train)\n",
    "X_valid=createDocWordMatrix(nfeatures, 53, X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W0 = torch.randn(5,nfeatures)*.01\n",
    "b0 =torch.zeros(5,1)*.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.766958182191\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58.700393812541\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59.907269773028\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59.484957267702\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "57.231146644799\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58.695047139257\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58.266739349158\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "58.164724926569\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "56.244766468513\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "56.12616590534\t\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p0 = torch.cat(W0,b0,2)\n",
    "rate = 0.001\n",
    "\n",
    "--d = torch.Tensor(50)\n",
    "for i = 1,10 do\n",
    "    --p0 = adam(p0)\n",
    "    p0 = sgd(p0)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "function predict(X, W, b)\n",
    "    local b = b:t()\n",
    "    return (X*W:t()):add(b:expand(b, X:size(1), b:size(2)))\n",
    "end\n",
    "function predict_score(ypred, ytrue)\n",
    "    local c = 0\n",
    "    for i=1,ypred:size(1) do\n",
    "        if ypred[i][1] == ytrue[i] then\n",
    "            c = c + 1       \n",
    "        end\n",
    "    end\n",
    "    return c/ypred:size(1)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    " --intercept\n",
    "b = p0:sub(1, p0:size(1), p0:size(2), p0:size(2))\n",
    "\n",
    "--coefficients\n",
    "W = p0:sub(1, p0:size(1), 1, p0:size(2)-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = predict(X_valid, W, b)\n",
    "_, score = torch.max(Y_pred, 2)\n",
    "--_,Y_true = torch.max(Y_valid, 2)\n",
    "acc_score = predict_score(score, Y_valid)\n",
    "print(acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
