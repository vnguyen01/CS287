{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('nn')\n",
    "require('hdf5')\n",
    "require('optim')\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "train_rnn_X = f:read('train_rnn_X'):all()\n",
    "train_rnn_Y = f:read('train_rnn_Y'):all()\n",
    "train_X_seqeuence =  f:read('train_X_sequence'):all()\n",
    "train_Y  = f:read('train_Y'):all()\n",
    "valid_reduced_X = f:read('valid_reduced_X'):all()\n",
    "valid_reduced_Y = f:read('valid_reduced_Y'):all()\n",
    "windows_train = f:read('windows_train'):all()\n",
    "windows_valid = f:read('windows_valid'):all()\n",
    "test = f:read('test'):all()\n",
    "valid_kaggle_with_spaces = f:read('valid_kaggle_with_spaces'):all()\n",
    "valid_kaggle_without_spaces = f:read('valid_kaggle_without_spaces'):all()\n",
    "valid_answers = f:read('valid_answers'):all()\n",
    "nfeatures = (f:read('nfeatures'):all())[1]\n",
    "nclasses = (f:read('nclasses'):all())[1]\n",
    "\n",
    "f:close()\n",
    "\n",
    "window_size = windows_train:size(2)\n",
    "n_actual = nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedded_size = 15\n",
    "D_h = 100\n",
    "\n",
    "lookup1 = nn.LookupTable(nfeatures*window_size,embedded_size)\n",
    "linear1 = nn.Linear(window_size*embedded_size, D_h)\n",
    "linear2 = nn.Linear(D_h, n_actual)\n",
    "h = nn.Sequential()\n",
    "h:add(lookup1)\n",
    "--lookup1.weight:renorm(2, 2, 1)\n",
    "h:add(nn.Reshape(window_size*embedded_size, True))\n",
    "h:add(linear1)\n",
    "h:add(nn.Tanh())\n",
    "h:add(linear2)\n",
    "h:add(nn.LogSoftMax())\n",
    "mse = nn.ClassNLLCriterion()\n",
    "--mse = nn.CrossEntropyCriterion()\n",
    "w, dl_dw = h:getParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_set = windows_train\n",
    "Y_set = train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 599905\n",
       "      2\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_train:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss for iteration 100 is 0.23900963315465\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 200 is 0.23902097132909\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 300 is 0.24802188778067\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 400 is 0.23186138448551\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 500 is 0.2417735744339\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 600 is 0.24147117033568\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 700 is 0.23492970381914\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 800 is 0.23004008082078\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 900 is 0.25461521100604\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1000 is 0.22018250712224\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1100 is 0.22873536573887\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1200 is 0.22574429610338\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1300 is 0.25823535711256\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1400 is 0.26511774346875\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1500 is 0.25003479659911\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1600 is 0.23998919922331\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1700 is 0.25260531777705\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1800 is 0.20667792134115\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 1900 is 0.25588309390427\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2000 is 0.25003180373727\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2100 is 0.24409919949395\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2200 is 0.23180793218036\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2300 is 0.23400054549858\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2400 is 0.25673399218752\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2500 is 0.19652156327513\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2600 is 0.26645682543458\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2700 is 0.24566500939144\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2800 is 0.24443433775536\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 2900 is 0.24173435534657\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 3000 is 0.24624991696695\t\n"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function feval(w_new)\n",
    "   \n",
    "    bsize= batch\n",
    "    local idx = torch.randperm(X_set:size(1)):sub(1,bsize)\n",
    "\n",
    "    local x = torch.Tensor(bsize, X_set:size(2))\n",
    "\n",
    "    \n",
    "    --y = y:reshape(Y_train:size(1), 1)\n",
    "    \n",
    "    local y_ = torch.Tensor(bsize, 1)\n",
    "\n",
    "    for i=1,bsize do\n",
    "        x[i] = X_set[idx[i]]\n",
    "        y_[i] = Y_set[idx[i]]\n",
    "    end\n",
    "    \n",
    "    y_ = y_:squeeze()\n",
    "    local inputs = x\n",
    "    local targets = y_\n",
    "    -- reset gradients (gradients are always accumulated, to accommodate\n",
    "    -- batch methods)\n",
    "    dl_dw:zero()\n",
    "    lookup1.weight:renorm(2, 1, 5)\n",
    "    -- evaluate the loss function and its derivative with respect to x, given a mini batch\n",
    "    local prediction = h:forward(inputs)\n",
    "    local loss_w = mse:forward(prediction, targets)\n",
    "    h:backward(inputs, mse:backward(prediction, targets))\n",
    "    \n",
    "    return loss_w, dl_dw\n",
    "            \n",
    "end\n",
    "\n",
    "batch = 1000\n",
    "\n",
    "-- cycle on data\n",
    "for i = 1,3000 do\n",
    "    -- train a mini_batch of batchSize in parallel\n",
    "    _, fs = optim.adam(feval,w)\n",
    "\n",
    "    if i % 100 == 0 then\n",
    "        print('loss for iteration ' .. i  .. ' is ' .. fs[1] )\n",
    "        -- print(sgd_params)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(input_set, output_set)\n",
    "    sum = 0\n",
    "    distributions = torch.Tensor(input_set:size(1),2)\n",
    "    for i = 1,1000 do\n",
    "        a = (h:forward(input_set[i]))\n",
    "        distribution = (nn.LogSoftMax():forward(a))\n",
    "        distributions[i] = torch.exp(distribution)\n",
    "        answer = distribution[output_set[i]]\n",
    "        sum = sum + answer\n",
    "        \n",
    "    end\n",
    "    return torch.exp(-sum/1000), distributions\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2642763110917\t\n"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perp, dist = perplexity(windows_valid:sub(1,windows_valid:size(1)), valid_reduced_Y)\n",
    "print(perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid_nospaces = pre_pad(valid_kaggle_without_spaces, windows_train:size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--Returns padded X_valid_nospaces for space count\n",
    "function pre_pad(x_valid_nospaces, w)\n",
    "    local padding = torch.Tensor(x_valid_nospaces:size(1), w-1):fill(30)\n",
    "    padding = padding:type('torch.LongTensor')\n",
    "    return torch.cat(padding, x_valid_nospaces, 2)\n",
    "end\n",
    "\n",
    "function NN_greedy(input_set, output_set)\n",
    "    sum = 0\n",
    "    distributions = torch.Tensor(input_set:size(1),2)\n",
    "    local mean_error_sq = 0\n",
    "    for i = 1,1000 do\n",
    "        \n",
    "        local spaces = 0\n",
    "        local sentence = input_set:sub(i,i,1,input_set:size(2)):clone()\n",
    "        \n",
    "        \n",
    "        for j=1,(input_set:size(2)-windows_train:size(2)) do\n",
    "            \n",
    "            if sentence[1][j+windows_train:size(2)] == 30 then\n",
    "                break\n",
    "            end\n",
    "            \n",
    "            local context = sentence:sub(1,1,j,j+windows_train:size(2)-1)\n",
    "            local p_space = torch.exp(h:forward(context))[1][2]\n",
    "            if p_space > 0.3 then\n",
    "                spaces = spaces + 1\n",
    "                for k=1,sentence:size(2)-j-windows_train:size(2) do\n",
    "                    local idx = sentence:size(2) - k\n",
    "                    sentence[1][idx+1] = sentence[1][idx]\n",
    "                end\n",
    "                sentence[1][j+windows_train:size(2)] = 30\n",
    "            end\n",
    "        end\n",
    "        mean_error_sq = mean_error_sq + (spaces - output_set[i])^2\n",
    "    end\n",
    "    return mean_error_sq/1000\n",
    "end\n",
    "\n",
    "function NN_dp(input_set, output_set)\n",
    "    sum = 0\n",
    "    distributions = torch.Tensor(input_set:size(1),2)\n",
    "    local mean_error_sq = 0\n",
    "    for i = 1,1000 do\n",
    "        \n",
    "        local spaces = 0\n",
    "        local sentence = input_set:sub(i,i,1,input_set:size(2)):clone()\n",
    "        \n",
    "        \n",
    "        for j=1,(input_set:size(2)-windows_train:size(2)) do\n",
    "            \n",
    "            if sentence[1][j+windows_train:size(2)] == 30 then\n",
    "                break\n",
    "            end\n",
    "            \n",
    "            local context = sentence:sub(1,1,j,j+windows_train:size(2)-1)\n",
    "            local p_space = torch.exp(h:forward(context))[1][2]\n",
    "            if p_space > 0.3 then\n",
    "                spaces = spaces + 1\n",
    "                for k=1,sentence:size(2)-j-windows_train:size(2) do\n",
    "                    local idx = sentence:size(2) - k\n",
    "                    sentence[1][idx+1] = sentence[1][idx]\n",
    "                end\n",
    "                sentence[1][j+windows_train:size(2)] = 30\n",
    "            end\n",
    "        end\n",
    "        mean_error_sq = mean_error_sq + (spaces - output_set[i])^2\n",
    "    end\n",
    "    return mean_error_sq/1000\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.685\t\n"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = greedy(X_valid_nospaces, valid_answers )\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 115716\n",
       "      5\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows_valid:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "  420\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_nospaces:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function write2file(scores, fname)\n",
    "    f = io.open(fname, \"w\")\n",
    "    f:write(\"ID,Class1,CLass2,Class3,Class4,Class5,Class6,Class7,Class8,Class9,Class10,Class11,Class12,CLass13,Class14,Class15,Class16,Class17,Class18,Class19,Class20,Class21,Class22,Class23,CLass24,Class25,Class26,Class27,Class28,Class29,Class30,Class31,Class32,Class33,Class34,CLass35,Class36,Class37,Class38,Class39,Class40,Class41,Class42,Class43,Class44,Class45,CLass46,Class47,Class48,Class49,Class50\\n\")\n",
    "    for i=1,scores:size(1) do\n",
    "        s = tostring(i)\n",
    "        for j=1, scores:size(2) do\n",
    "            s = s .. \",\" .. tostring(scores[i][j])\n",
    "        end\n",
    "        f:write(s .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write2file(distributions, 'predictions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
