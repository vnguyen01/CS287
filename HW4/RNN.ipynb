{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('rnn')\n",
    "require('hdf5')\n",
    "require('optim')\n",
    "\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "\n",
    "\n",
    "train_rnn_X = f:read('train_rnn_X'):all()\n",
    "train_rnn_Y = f:read('train_rnn_Y'):all()\n",
    "train_X_sequence =  f:read('train_X_sequence'):all()\n",
    "train_Y  = f:read('train_Y'):all()\n",
    "valid_reduced_X = f:read('valid_reduced_X'):all()\n",
    "valid_reduced_Y = f:read('valid_reduced_Y'):all()\n",
    "windows_train = f:read('windows_train'):all()\n",
    "windows_valid = f:read('windows_valid'):all()\n",
    "test = f:read('test'):all()\n",
    "valid_kaggle_with_spaces = f:read('valid_kaggle_with_spaces'):all()\n",
    "valid_kaggle_without_spaces = f:read('valid_kaggle_without_spaces'):all()\n",
    "valid_answers = f:read('valid_answers'):all()\n",
    "nfeatures = (f:read('nfeatures'):all())[1]\n",
    "nclasses = (f:read('nclasses'):all())[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f:close()\n",
    "\n",
    "window_size = windows_train:size(2)\n",
    "n_actual = nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = nfeatures\n",
    "embed_dim = 15\n",
    "lin_dim = 100\n",
    "LT = nn.LookupTable(vocab_size, embed_dim)\n",
    "\n",
    "lstm = nn.Sequential()\n",
    "lstm:add(LT)\n",
    "--lstm:add(nn.Dropout())\n",
    "lstm:add(nn.SplitTable(1, 3))\n",
    "seqLSTM = nn.Sequencer(nn.LSTM(embed_dim, lin_dim))\n",
    "seqLSTM:add(nn.Dropout())\n",
    "seqLSTM:remember('both')\n",
    "lstm:add(seqLSTM)\n",
    "\n",
    "lstm:add(nn.Sequencer(nn.Linear(lin_dim, n_actual)))\n",
    "\n",
    "--lstm:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "--crit = nn.SequencerCriterion(nn.BCECriterion())\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.CrossEntropyCriterion())\n",
    "params, grad_params = lstm:getParameters()\n",
    "params:rand(params:size()):csub(.5):mul(.05)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss for iteration 10 is 0.98731130227461\t10\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 20 is 0.65161224485017\t20\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 30 is 1.0223166355632\t30\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 40 is 0.98401989035034\t40\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 50 is 1.0449116013892\t50\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 60 is 0.68566530344512\t"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "60\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 70 is 0.83409786005037\t70\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 80 is 0.93282970194949\t80\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 90 is 0.85477172409615\t90\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 100 is 0.86734904318091\t100\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 110 is 0.71199206541105\t110\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 120 is 0.89627483117292\t120\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 130 is 0.72920245487203\t130\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 140 is 0.77295637383693\t140\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 150 is 0.70516244392505\t150\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 160 is 0.84481380576018\t160\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 170 is 0.71160987983189\t170\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 180 is 0.8230963582111\t180\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 190 is 0.80611638590276\t190\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 200 is 0.87019495507218\t200\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 210 is 0.81260439297206\t210\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 220 is 0.77501500330303\t220\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 230 is 0.73191985160177\t230\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 240 is 0.75605674732105\t240\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 250 is 1.006014589916\t250\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 260 is 0.77482965646521\t260\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 270 is 0.89605909708272\t270\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 280 is 0.88096955143646\t280\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 290 is 0.72399055591513\t290\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 300 is 0.94446703353276\t300\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 310 is 1.0864046492118\t310\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 320 is 0.89838511692538\t320\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 330 is 1.0212359581147\t330\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 340 is 0.67817013814407\t340\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 350 is 0.71473707370769\t350\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 360 is 0.81539030156475\t360\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 370 is 0.93442374663543\t370\t\n"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqLSTM:forget()\n",
    "count = 0\n",
    "function feval(w_new)\n",
    " \n",
    "    --count = count + 1\n",
    "    count = math.fmod(count + 1,train_rnn_X:size(1))\n",
    "    if count == 0 then\n",
    "        count = 1\n",
    "        seqLSTM:forget()\n",
    "    end\n",
    "    \n",
    "    x_d = (train_rnn_X[count]):t()\n",
    "    y_d = (train_rnn_Y[count]):t()\n",
    "    \n",
    "    \n",
    "    grad_params:zero()\n",
    "    preds = lstm:forward(x_d)\n",
    "    --print(preds[1])\n",
    "    loss = crit:forward(preds, y_d)\n",
    "    grad_out = crit:backward(preds, y_d)\n",
    "    \n",
    "    lstm:backward(x_d, grad_out)\n",
    "    \n",
    "    if torch.norm(grad_params) > 5 then\n",
    "        nn.Normalize(2):forward(grad_params)\n",
    "        grad_params:mul(5)\n",
    "    end\n",
    "    \n",
    "    return loss, grad_params\n",
    "end\n",
    "\n",
    "for i = 1,40000 do\n",
    "    -- train a mini_batch of batchSize in parallel\n",
    "    _, fs = optim.adam(feval,params)\n",
    "    if i % 10 == 0 then\n",
    "        print('loss for iteration ' .. i  .. ' is ' .. fs[1] , count)\n",
    "        \n",
    "        -- print(sgd_params)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(input_set, output_set)\n",
    "    sum = 0\n",
    "    seqLSTM:forget()\n",
    "    distributions = torch.Tensor(input_set:size(1),2)\n",
    "    for i = 1,input_set:size(1) do\n",
    "        \n",
    "        a = lstm:forward(input_set:sub(i,i))\n",
    "        \n",
    "        distribution = (nn.LogSoftMax():forward(a[1]))\n",
    "        \n",
    "        distributions[i] = torch.exp(distribution)\n",
    "        answer = distribution[output_set[i]]\n",
    "        sum = sum + answer\n",
    "        \n",
    "    end\n",
    "    return torch.exp(-sum/input_set:size(1)), distributions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.168772848808\t\n"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = perplexity((valid_reduced_X:sub(1,100000)), valid_reduced_Y)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.092589718542\t\n"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = perplexity((train_X_sequence:sub(1,10000)), train_Y:sub(1,100000))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict(input_set, output_set, cutoff)\n",
    "    kaggle = torch.zeros(input_set:size(1))\n",
    "    for i = 1,input_set:size(1) do\n",
    "        count = 0\n",
    "        lstm:forget()\n",
    "        for j = 1, input_set:size(2) do\n",
    "            if input_set[i][j] == 30 then\n",
    "                \n",
    "                break\n",
    "            end\n",
    "            a = lstm:forward(torch.Tensor{input_set[i][j]})\n",
    "            \n",
    "            distribution = (nn.LogSoftMax():forward(a[1]))\n",
    "            distribution = torch.exp(distribution)\n",
    "            \n",
    "            if distribution[2] > cutoff then\n",
    "                space = lstm:forward(torch.Tensor{28})\n",
    "                count = count + 1\n",
    "            end\n",
    "            \n",
    "        \n",
    "        end\n",
    "        kaggle[i] = count\n",
    "    \n",
    "    end\n",
    "    if output_set ~= 0 then\n",
    "        out =output_set:double()\n",
    "        MSE = nn.MSECriterion():forward(kaggle, out)\n",
    "    else\n",
    "        out = 0\n",
    "        MSE = 0\n",
    "    end\n",
    "    \n",
    "    return kaggle, out, MSE\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k, o, mse = predict(valid_kaggle_without_spaces:sub(1,1000), valid_answers:sub(1,1000),.22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.525\t\n"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k,_,_ = predict(test, 0, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function write2file(scores, fname)\n",
    "    f = io.open(fname, \"w\")\n",
    "    f:write(\"ID,Count\\n\")\n",
    "    for i=1,scores:size(1) do\n",
    "        s = tostring(i) .. \",\" .. tostring(scores[i])\n",
    "        f:write(s .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end\n",
    "\n",
    "write2file(k, 'preds.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3370\n",
       "  416\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_kaggle_with_spaces:size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 1x2\n",
       "  2 : DoubleTensor - size: 1x2\n",
       "  3 : DoubleTensor - size: 1x2\n",
       "  4 : DoubleTensor - size: 1x2\n",
       "  5 : DoubleTensor - size: 1x2\n",
       "  6 : DoubleTensor - size: 1x2\n",
       "  7 : DoubleTensor - size: 1x2\n",
       "  8 : DoubleTensor - size: 1x2\n",
       "  9 : DoubleTensor - size: 1x2\n",
       "  10 : DoubleTensor - size: 1x2\n",
       "}\n"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "bad argument #2 to '?' (out of range at /Users/austinshin/torch/pkg/torch/generic/Tensor.c:890)\nstack traceback:\n\t[C]: at 0x0cf96ad0\n\t[C]: in function '__index'\n\t[string \"function predict(input_set, output_set, cutof...\"]:11: in function 'f'\n\t[string \"local f = function() return predict(valid_kag...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:209: in function <...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t...s/austinshin/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010cc0dbc0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "bad argument #2 to '?' (out of range at /Users/austinshin/torch/pkg/torch/generic/Tensor.c:890)\nstack traceback:\n\t[C]: at 0x0cf96ad0\n\t[C]: in function '__index'\n\t[string \"function predict(input_set, output_set, cutof...\"]:11: in function 'f'\n\t[string \"local f = function() return predict(valid_kag...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:209: in function <...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:173>\n\t...s/austinshin/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...ustinshin/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t...s/austinshin/torch/install/share/lua/5.1/itorch/main.lua:381: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x010cc0dbc0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
