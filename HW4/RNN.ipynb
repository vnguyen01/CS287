{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('rnn')\n",
    "require('hdf5')\n",
    "require('optim')\n",
    "\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "\n",
    "\n",
    "train_rnn_X = f:read('train_rnn_X'):all()\n",
    "train_rnn_Y = f:read('train_rnn_Y'):all()\n",
    "train_X_sequence =  f:read('train_X_sequence'):all()\n",
    "train_Y  = f:read('train_Y'):all()\n",
    "valid_reduced_X = f:read('valid_reduced_X'):all()\n",
    "valid_reduced_Y = f:read('valid_reduced_Y'):all()\n",
    "windows_train = f:read('windows_train'):all()\n",
    "windows_valid = f:read('windows_valid'):all()\n",
    "test = f:read('test'):all()\n",
    "valid_kaggle_with_spaces = f:read('valid_kaggle_with_spaces'):all()\n",
    "valid_kaggle_without_spaces = f:read('valid_kaggle_without_spaces'):all()\n",
    "valid_answers = f:read('valid_answers'):all()\n",
    "nfeatures = (f:read('nfeatures'):all())[1]\n",
    "nclasses = (f:read('nclasses'):all())[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f:close()\n",
    "\n",
    "window_size = windows_train:size(2)\n",
    "n_actual = nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_size = nfeatures\n",
    "embed_dim = 15\n",
    "lin_dim = 100\n",
    "LT = nn.LookupTable(vocab_size, embed_dim)\n",
    "\n",
    "lstm = nn.Sequential()\n",
    "lstm:add(LT)\n",
    "--lstm:add(nn.Dropout())\n",
    "lstm:add(nn.SplitTable(1, 3))\n",
    "seqLSTM = nn.Sequencer(nn.LSTM(embed_dim, lin_dim))\n",
    "seqLSTM:add(nn.Dropout())\n",
    "seqLSTM:remember('both')\n",
    "lstm:add(seqLSTM)\n",
    "\n",
    "lstm:add(nn.Sequencer(nn.Linear(lin_dim, n_actual)))\n",
    "\n",
    "--lstm:add(nn.Sequencer(nn.LogSoftMax()))\n",
    "\n",
    "--crit = nn.SequencerCriterion(nn.BCECriterion())\n",
    "\n",
    "crit = nn.SequencerCriterion(nn.CrossEntropyCriterion())\n",
    "params, grad_params = lstm:getParameters()\n",
    "params:rand(params:size()):csub(.5):mul(.05)\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seqLSTM:forget()\n",
    "count = 0\n",
    "function feval(w_new)\n",
    " \n",
    "    --count = count + 1\n",
    "    count = math.fmod(count + 1,train_rnn_X:size(1))\n",
    "    if count == 0 then\n",
    "        count = 1\n",
    "        seqLSTM:forget()\n",
    "    end\n",
    "    \n",
    "    x_d = (train_rnn_X[count]):t()\n",
    "    y_d = (train_rnn_Y[count]):t()\n",
    "    \n",
    "    \n",
    "    grad_params:zero()\n",
    "    preds = lstm:forward(x_d)\n",
    "    --print(preds[1])\n",
    "    loss = crit:forward(preds, y_d)\n",
    "    grad_out = crit:backward(preds, y_d)\n",
    "    \n",
    "    lstm:backward(x_d, grad_out)\n",
    "    \n",
    "    if torch.norm(grad_params) > 5 then\n",
    "        nn.Normalize(2):forward(grad_params)\n",
    "        grad_params:mul(5)\n",
    "    end\n",
    "    \n",
    "    return loss, grad_params\n",
    "end\n",
    "\n",
    "for i = 1,1000 do\n",
    "    -- train a mini_batch of batchSize in parallel\n",
    "    _, fs = optim.adam(feval,params)\n",
    "    if i % 100 == 0 then\n",
    "        print('loss for iteration ' .. i  .. ' is ' .. fs[1] , count)\n",
    "        \n",
    "        -- print(sgd_params)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(input_set, output_set)\n",
    "    sum = 0\n",
    "    seqLSTM:forget()\n",
    "    distributions = torch.Tensor(input_set:size(1),2)\n",
    "    for i = 1,input_set:size(1) do\n",
    "        \n",
    "        a = lstm:forward(input_set:sub(i,i))\n",
    "        \n",
    "        distribution = (nn.LogSoftMax():forward(a[1]))\n",
    "        \n",
    "        distributions[i] = torch.exp(distribution)\n",
    "        answer = distribution[output_set[i]]\n",
    "        sum = sum + answer\n",
    "        \n",
    "    end\n",
    "    return torch.exp(-sum/input_set:size(1)), distributions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b = perplexity((valid_reduced_X:sub(1,10000)), valid_reduced_Y)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a,b = perplexity((train_X_sequence:sub(1,10000)), train_Y:sub(1,100000))\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function predict(input_set, output_set, cutoff)\n",
    "    kaggle = torch.zeros(input_set:size(1))\n",
    "    for i = 1,input_set:size(1) do\n",
    "        count = 0\n",
    "        lstm:forget()\n",
    "        for j = 1, input_set:size(2) do\n",
    "            if input_set[i][j] == 30 then\n",
    "                \n",
    "                break\n",
    "            end\n",
    "            a = lstm:forward(torch.Tensor{input_set[i][j]})\n",
    "            \n",
    "            distribution = (nn.LogSoftMax():forward(a[1]))\n",
    "            distribution = torch.exp(distribution)\n",
    "            \n",
    "            if distribution[2] > cutoff then\n",
    "                space = lstm:forward(torch.Tensor{28})\n",
    "                count = count + 1\n",
    "            end\n",
    "            \n",
    "        \n",
    "        end\n",
    "        kaggle[i] = count\n",
    "    \n",
    "    end\n",
    "    if output_set ~= 0 then\n",
    "        out =output_set:double()\n",
    "        MSE = nn.MSECriterion():forward(kaggle, out)\n",
    "    else\n",
    "        out = 0\n",
    "        MSE = 0\n",
    "    end\n",
    "    \n",
    "    return kaggle, out, MSE\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k, o, mse = predict(valid_kaggle_without_spaces, valid_answers,.24)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k,_,_ = predict(test, 0, .24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function write2file(scores, fname)\n",
    "    f = io.open(fname, \"w\")\n",
    "    f:write(\"ID,Count\\n\")\n",
    "    for i=1,scores:size(1) do\n",
    "        s = tostring(i) .. \",\" .. tostring(scores[i])\n",
    "        f:write(s .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end\n",
    "\n",
    "write2file(k, 'preds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
