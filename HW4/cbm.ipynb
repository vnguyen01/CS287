{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'math'\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"windows_train\"):all()\n",
    "Y_train = f:read(\"train_Y\"):all()\n",
    "\n",
    "X_valid = f:read(\"windows_valid\"):all()\n",
    "X_valid_nospaces = f:read(\"valid_kaggle_without_spaces\"):all()\n",
    "\n",
    "Y_valid = f:read(\"valid_reduced_Y\"):all()\n",
    "Y_valid_spaces = f:read(\"valid_answers\"):all()\n",
    "\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--Returns converted LongTensor to Str split by space row-wise\n",
    "function createHash(longTensor) \n",
    "    local s = \"\"\n",
    "    for i=1,longTensor:size(1) do\n",
    "        s = s .. tostring(longTensor[i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "--Returns converted LongTensor to Str split by space col-wise\n",
    "function createHash2(longTensor)\n",
    "    local s = \"\"\n",
    "    for i=1,longTensor:size(2) do\n",
    "        s = s .. tostring(longTensor[1][i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "--Return added padding when necessary at </s>\n",
    "function add_padding(r, n, win) \n",
    "    if r < n then\n",
    "        for i=1,n-r do\n",
    "            win[i] = 30\n",
    "        end\n",
    "        r = r + 1\n",
    "    end\n",
    "    if win[n] == 30 then\n",
    "        r = 1\n",
    "    end\n",
    "    return r, win\n",
    "end\n",
    "\n",
    "--Returns table of space and total counts\n",
    "function count_train(windows_train, space_train, n_gram)\n",
    "    local count_table = {}\n",
    "    local space_table = {}\n",
    "    local restart = 1\n",
    "    for i=1,windows_train:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_train[i])\n",
    "        local key = createHash(padded)\n",
    "        if count_table[key] then\n",
    "            count_table[key] = count_table[key] + 1\n",
    "        else\n",
    "            count_table[key] = 1\n",
    "            space_table[key] = 0\n",
    "        end\n",
    "        if space_train[i] == 2 then\n",
    "            space_table[key] = space_table[key] + 1\n",
    "        end\n",
    "    end\n",
    "    return space_table, count_table\n",
    "end  \n",
    "\n",
    "--Returns normalized probability for two scores\n",
    "function normalize(num, den) \n",
    "    return num/(num+den)\n",
    "end\n",
    "\n",
    "--Returns smoothed counts\n",
    "function laplace_smooth(count, total, alpha, vocab_size)\n",
    "    return (count+alpha)/(total+alpha*vocab_size)\n",
    "end\n",
    "\n",
    "--Returns perplexity for CBM\n",
    "function count_perp(space_table, total_table, windows_valid, space_valid, n_gram, alpha, vocab_size)\n",
    "    local restart = 1\n",
    "    local perp = 0\n",
    "    for i=1,windows_valid:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_valid[i])\n",
    "        local key = createHash(padded)\n",
    "        if total_table[key] then\n",
    "            local p_space = laplace_smooth(space_table[key], total_table[key], alpha, vocab_size)\n",
    "            local p_nospace = laplace_smooth(total_table[key] - space_table[key], total_table[key], alpha, vocab_size)\n",
    "            \n",
    "            --Next char is NOT space\n",
    "            if space_valid[i] == 1 then\n",
    "                perp = perp + math.log(normalize(p_nospace, p_space))\n",
    "            --Next char IS space\n",
    "            else\n",
    "                perp = perp + math.log(normalize(p_space, p_nospace))\n",
    "            end\n",
    "        else\n",
    "            --Probability for unseen counts\n",
    "            perp = perp + math.log(alpha/vocab_size)\n",
    "        end\n",
    "    end\n",
    "    return math.exp(-perp/windows_valid:size(1))\n",
    "end\n",
    "\n",
    "--Returns array of perplexity scores for different alphas\n",
    "function count_based_CV(space_table, total_table, x_valid, y_valid, w, a, n)\n",
    "    local list=\"\"\n",
    "    for i=1,100 do\n",
    "        local a = i/10\n",
    "        local perplexity = count_perp(space_table, total_table, x_valid, y_valid, w, a, n)\n",
    "        list=list..tostring(perplexity)..\",\"\n",
    "    end\n",
    "    return list\n",
    "end\n",
    "\n",
    "--Returns padded X_valid_nospaces for space count\n",
    "function pre_pad(x_valid_nospaces, w)\n",
    "    local padding = torch.Tensor(x_valid_nospaces:size(1), w-1):fill(30)\n",
    "    padding = padding:type('torch.LongTensor')\n",
    "    return torch.cat(padding, x_valid_nospaces, 2)\n",
    "end\n",
    "\n",
    "--\n",
    "function count_space_predict(space_table, total_table, x_valid, y_valid, w, n, a)\n",
    "    for i=1,x_valid:size(1) do\n",
    "        for j=1,x_valid:size(2)-w+1 do\n",
    "            local context = x_valid:sub(i,i,j,j+w-1)\n",
    "            local key = createHash2(context)\n",
    "            if total_table[key] then\n",
    "                local p_space = laplace_smooth(space_table[key], total_table[key], a, n)\n",
    "                local p_nospace = laplace_smooth(total_table[key] - space_table[key], total_table[key], a, n)\n",
    "                local p_space = normalize(p_space, p_nospace)\n",
    "                \n",
    "                if p_space > 0.5 then\n",
    "                    --Loop through backwards from the second to last entry up to position of next space\n",
    "                    for k=1,x_valid:size(2)-j-w do\n",
    "                        local idx = x_valid:size(2) - k\n",
    "                        x_valid[i][idx+1] = x_valid[i][idx]\n",
    "                        --x_valid:sub(i,i,idx+1,idx+1) =  x_valid:sub(i,i,idx,idx)\n",
    "                    end\n",
    "                    x_valid[i][j+w] = 30\n",
    "                end\n",
    "            \n",
    "            end\n",
    "        print(x_valid[i])\n",
    "        break\n",
    "        end\n",
    "    break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win_size = X_train:size(2)\n",
    "ngram_space, ngram_total = count_train(X_train, Y_train, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COUNT BASED MODEL\t\n",
       "================================\t\n",
       "Window size: 3\t\n",
       "Laplace smoothing parameter: 1\t\n",
       "Perplexity: 1.1981899697832\t\n"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additive = 1\n",
    "perplexity = count_perp(ngram_space, ngram_total, X_valid, Y_valid, win_size, additive, nfeatures)\n",
    "\n",
    "print(\"COUNT BASED MODEL\")\n",
    "print(\"================================\")\n",
    "print(\"Window size: \" .. tostring(win_size))\n",
    "print(\"Laplace smoothing parameter: \" .. tostring(additive))\n",
    "print(\"Perplexity: \" .. tostring(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_valid_nospaces = pre_pad(X_valid_nospaces, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 30\n",
       " 30\n",
       "  2\n",
       " 14\n",
       " 15\n",
       " 18\n",
       " 20\n",
       " 12\n",
       "  4\n",
       " 19\n",
       " 18\n",
       " 12\n",
       "  1\n",
       " 24\n",
       " 22\n",
       "  1\n",
       " 15\n",
       " 21\n",
       " 21\n",
       " 14\n",
       " 12\n",
       " 14\n",
       " 23\n",
       "  4\n",
       " 21\n",
       "  9\n",
       "  4\n",
       "  8\n",
       " 19\n",
       " 21\n",
       "  4\n",
       " 13\n",
       "  4\n",
       " 17\n",
       "  9\n",
       " 14\n",
       " 15\n",
       "  4\n",
       " 18\n",
       "  1\n",
       " 13\n",
       "  8\n",
       " 21\n",
       " 21\n",
       " 13\n",
       "  4\n",
       "  2\n",
       " 13\n",
       " 14\n",
       " 18\n",
       "  4\n",
       " 19\n",
       " 21\n",
       " 14\n",
       " 21\n",
       "  9\n",
       "  4\n",
       " 21\n",
       " 23\n",
       " 18\n",
       "  4\n",
       " 21\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       " 30\n",
       "[torch.LongTensor of size 418]\n",
       "\n",
       "\n"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_space_predict(ngram_space, ngram_total, X_valid_nospaces, Y_valid, win_size, nfeatures, additive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function createHash2(longTensor) \n",
    "    local s = \"\"\n",
    "    for i=1,longTensor:size(2) do\n",
    "        s = s .. tostring(longTensor[1][i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "vocab_size = nfeatures\n",
    "for i=1,X_valid_nospaces:size(1) do\n",
    "    \n",
    "    local sen = X_valid_nospaces:sub(i,i,1,X_valid_nospaces:size(2))\n",
    "    \n",
    "    local flag = true\n",
    "    local idx = 1\n",
    "    \n",
    "    while flag do\n",
    "        \n",
    "        local win = sen:sub(i,i,idx, idx+win_size-1)\n",
    "        local after = sen:sub(i,i,idx+win_size, sen:size(2))\n",
    "        \n",
    "        local key = createHash2(win)\n",
    "        if ngram_total[key] then\n",
    "            local p_space = laplace_smooth(ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_nospace = laplace_smooth(ngram_total[key] - ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_space = normalize(p_space, p_nospace)\n",
    "            if p_space > 0.5 then\n",
    "                print(\"space\")\n",
    "                local temp = torch.cat(win, torch.LongTensor(torch.LongStorage{30}))\n",
    "                sen = torch.cat(temp, after)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        idx = idx + 1\n",
    "        \n",
    "        print(sen:sub(i,i,idx,idx+win_size))\n",
    "        --print(sen:sub(i,i,idx, idx+win_size))\n",
    "        if sen:sub(i,i,idx+win_size,idx+win_size)[1][1] == 30 then\n",
    "            \n",
    "            flag = false\n",
    "        end\n",
    "\n",
    "    end\n",
    "    break\n",
    "        \n",
    "        \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "    end\n",
    "    \n",
    "    for j=1,X_valid_nospaces:size(2) do\n",
    "        if X_valid_nospaces:sub(i,i,j+win_size-1,j+win_size-1)[1][1] == 30 then\n",
    "            break\n",
    "        end\n",
    "        local win = X_valid_nospaces:sub(i,i,j,j+win_size-1)\n",
    "        local key = createHash2(win)\n",
    "        --print(key)\n",
    "        sen = sen .. key\n",
    "        if ngram_total[key] then\n",
    "            local p_space = laplace_smooth(ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_nospace = laplace_smooth(ngram_total[key] - ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            p_space = (normalize(p_space, p_nospace))\n",
    "            if p_space > 0.5 then\n",
    "                sen = sen .. \"30 \"\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    print(sen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j=3,1 do\n",
    "    print(j)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
