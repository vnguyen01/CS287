{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'math'\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"windows_train\"):all()\n",
    "Y_train = f:read(\"train_Y\"):all()\n",
    "X_valid = f:read(\"windows_valid\"):all()\n",
    "X_valid_nospaces = f:read(\"valid_kaggle_without_spaces\"):all()\n",
    "Y_valid = f:read(\"valid_reduced_Y\"):all()\n",
    "Y_valid_spaces = f:read(\"valid_answers\"):all()\n",
    "\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--Returns converted LongTensor to Str split by space\n",
    "function createHash(longTensor) \n",
    "    s = \"\"\n",
    "    for i=1,longTensor:size(1) do\n",
    "        s = s .. tostring(longTensor[i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "--Return added padding when necessary at </s>\n",
    "function add_padding(r, n, win) \n",
    "    if r < n then\n",
    "        for i=1,n-r do\n",
    "            win[i] = 30\n",
    "        end\n",
    "        r = r + 1\n",
    "    end\n",
    "    if win[n] == 30 then\n",
    "        r = 1\n",
    "    end\n",
    "    return r, win\n",
    "end\n",
    "\n",
    "--Returns table of space and total counts\n",
    "function count_train(windows_train, space_train, n_gram)\n",
    "    local count_table = {}\n",
    "    local space_table = {}\n",
    "    local restart = 1\n",
    "    for i=1,windows_train:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_train[i])\n",
    "        local key = createHash(padded)\n",
    "        if count_table[key] then\n",
    "            count_table[key] = count_table[key] + 1\n",
    "        else\n",
    "            count_table[key] = 1\n",
    "            space_table[key] = 0\n",
    "        end\n",
    "        if space_train[i] == 2 then\n",
    "            space_table[key] = space_table[key] + 1\n",
    "        end\n",
    "    end\n",
    "    return space_table, count_table\n",
    "end  \n",
    "\n",
    "--Returns normalized probability for two scores\n",
    "function normalize(num, den) \n",
    "    return num/(num+den)\n",
    "end\n",
    "\n",
    "--Returns smoothed counts\n",
    "function laplace_smooth(count, total, alpha, vocab_size)\n",
    "    return (count+alpha)/(total+alpha*vocab_size)\n",
    "end\n",
    "\n",
    "--Returns perplexity for CBM\n",
    "function count_perp(space_table, total_table, windows_valid, space_valid, n_gram, alpha, vocab_size)\n",
    "    local restart = 1\n",
    "    local perp = 0\n",
    "    for i=1,windows_valid:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_valid[i])\n",
    "        local key = createHash(padded)\n",
    "        if total_table[key] then\n",
    "            local p_space = laplace_smooth(space_table[key], total_table[key], alpha, vocab_size)\n",
    "            local p_nospace = laplace_smooth(total_table[key] - space_table[key], total_table[key], alpha, vocab_size)\n",
    "            \n",
    "            --Next char is NOT space\n",
    "            if space_valid[i] == 1 then\n",
    "                perp = perp + math.log(normalize(p_nospace, p_space))\n",
    "            --Next char IS space\n",
    "            else\n",
    "                perp = perp + math.log(normalize(p_space, p_nospace))\n",
    "            end\n",
    "        else\n",
    "            --Probability for unseen counts\n",
    "            perp = perp + math.log(alpha/vocab_size)\n",
    "        end\n",
    "    end\n",
    "    return math.exp(-perp/windows_valid:size(1))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win_size = X_train:size(2)\n",
    "ngram_space, ngram_total = count_train(X_train, Y_train, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COUNT BASED MODEL\t\n",
       "================================\t\n",
       "Window size: 3\t\n",
       "Laplace smoothing parameter: 1\t\n",
       "Perplexity: 1.1981899697832\t\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additive = 1\n",
    "perplexity = count_perp(ngram_space, ngram_total, X_valid, Y_valid, win_size, additive, nfeatures)\n",
    "\n",
    "print(\"COUNT BASED MODEL\")\n",
    "print(\"================================\")\n",
    "print(\"Window size: \" .. tostring(win_size))\n",
    "print(\"Laplace smoothing parameter: \" .. tostring(additive))\n",
    "print(\"Perplexity: \" .. tostring(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list=\"\"\n",
    "for i=1,100 do\n",
    "    additive = i/10\n",
    "    perplexity = count_perp(ngram_space, ngram_total, X_valid, Y_valid, win_size, additive, nfeatures)\n",
    "    list=list..tostring(perplexity)..\",\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padding = torch.Tensor(X_valid_nospaces:size(1), win_size-1):fill(30)\n",
    "padding = padding:type('torch.LongTensor')\n",
    "X_valid_nospaces = torch.cat(padding, X_valid_nospaces, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 20\n",
       "  2  14  15  30  18  20  12   4  19  18  12   1  24  22   1  15  21  21  14  12\n",
       "\n",
       "Columns 21 to 40\n",
       " 14  23   4  21   9   4   8  19  21   4  13   4  17   9  14  15   4  18   1  13\n",
       "\n",
       "Columns 41 to 60\n",
       "  8  21  21  13   4   2  13  14  18   4  19  21  14  21   9   4  21  23  18   4\n",
       "\n",
       "Columns 61 to 80\n",
       " 21  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 81 to 100\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 101 to 120\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 121 to 140\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 141 to 160\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 161 to 180\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 181 to 200\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 201 to 220\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 221 to 240\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 241 to 260\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 261 to 280\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 281 to 300\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 301 to 320\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 321 to 340\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 341 to 360\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 361 to 380\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 381 to 400\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "\n",
       "Columns 401 to 417\n",
       " 30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30  30\n",
       "[torch.LongTensor of size 1x417]\n",
       "\n"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createHash2(longTensor) \n",
    "    local s = \"\"\n",
    "    for i=1,longTensor:size(2) do\n",
    "        s = s .. tostring(longTensor[1][i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "vocab_size = nfeatures\n",
    "for i=1,X_valid_nospaces:size(1) do\n",
    "    \n",
    "    local sen = X_valid_nospaces:sub(i,i,1,X_valid_nospaces:size(2))\n",
    "    \n",
    "    local flag = true\n",
    "    local idx = 1\n",
    "    \n",
    "    \n",
    "    while flag do\n",
    "        local win = (sen:sub(1,1,idx, idx+win_size-1))\n",
    "        local after = sen:sub(1,1,idx+win_size, sen:size(2))\n",
    "        \n",
    "        local key = createHash2(win)\n",
    "        \n",
    "        \n",
    "        sen = torch.cat(win, torch.LongTensor(torch.LongStorage{30}))\n",
    "        sen = torch.cat(sen, after)\n",
    "        idx = idx + 1\n",
    "        print(sen)\n",
    "        break\n",
    "    end\n",
    "    break\n",
    "        \n",
    "        \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat(torch.Tensor{1}, torch.Tensor{2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "        \n",
    "    end\n",
    "    \n",
    "    for j=1,X_valid_nospaces:size(2) do\n",
    "        if X_valid_nospaces:sub(i,i,j+win_size-1,j+win_size-1)[1][1] == 30 then\n",
    "            break\n",
    "        end\n",
    "        local win = X_valid_nospaces:sub(i,i,j,j+win_size-1)\n",
    "        local key = createHash2(win)\n",
    "        --print(key)\n",
    "        sen = sen .. key\n",
    "        if ngram_total[key] then\n",
    "            local p_space = laplace_smooth(ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_nospace = laplace_smooth(ngram_total[key] - ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            p_space = (normalize(p_space, p_nospace))\n",
    "            if p_space > 0.5 then\n",
    "                sen = sen .. \"30 \"\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    print(sen)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       "[torch.LongTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
