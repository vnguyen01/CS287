{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'hdf5'\n",
    "require 'math'\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"windows_train\"):all()\n",
    "Y_train = f:read(\"train_Y\"):all()\n",
    "X_valid = f:read(\"windows_valid\"):all()\n",
    "X_valid_nospaces = f:read(\"valid_kaggle_without_spaces\"):all()\n",
    "Y_valid = f:read(\"valid_reduced_Y\"):all()\n",
    "Y_valid_spaces = f:read(\"valid_answers\"):all()\n",
    "\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "\n",
    "f:close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--Returns converted LongTensor to Str split by space\n",
    "function createHash(longTensor) \n",
    "    s = \"\"\n",
    "    for i=1,longTensor:size(1) do\n",
    "        s = s .. tostring(longTensor[i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "\n",
    "--Return added padding when necessary at </s>\n",
    "function add_padding(r, n, win) \n",
    "    if r < n then\n",
    "        for i=1,n-r do\n",
    "            win[i] = 30\n",
    "        end\n",
    "        r = r + 1\n",
    "    end\n",
    "    if win[n] == 30 then\n",
    "        r = 1\n",
    "    end\n",
    "    return r, win\n",
    "end\n",
    "\n",
    "--Returns table of space and total counts\n",
    "function count_train(windows_train, space_train, n_gram)\n",
    "    local count_table = {}\n",
    "    local space_table = {}\n",
    "    local restart = 1\n",
    "    for i=1,windows_train:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_train[i])\n",
    "        local key = createHash(padded)\n",
    "        if count_table[key] then\n",
    "            count_table[key] = count_table[key] + 1\n",
    "        else\n",
    "            count_table[key] = 1\n",
    "            space_table[key] = 0\n",
    "        end\n",
    "        if space_train[i] == 2 then\n",
    "            space_table[key] = space_table[key] + 1\n",
    "        end\n",
    "    end\n",
    "    return space_table, count_table\n",
    "end  \n",
    "\n",
    "--Returns normalized probability for two scores\n",
    "function normalize(num, den) \n",
    "    return num/(num+den)\n",
    "end\n",
    "\n",
    "--Returns smoothed counts\n",
    "function laplace_smooth(count, total, alpha, vocab_size)\n",
    "    return (count+alpha)/(total+alpha*vocab_size)\n",
    "end\n",
    "\n",
    "--Returns perplexity for CBM\n",
    "function count_perp(space_table, total_table, windows_valid, space_valid, n_gram, alpha, vocab_size)\n",
    "    local restart = 1\n",
    "    local perp = 0\n",
    "    for i=1,windows_valid:size(1) do\n",
    "        --Checks if a </s> is necessary (only for CBM!)\n",
    "        restart, padded = add_padding(restart, n_gram, windows_valid[i])\n",
    "        local key = createHash(padded)\n",
    "        if total_table[key] then\n",
    "            local p_space = laplace_smooth(space_table[key], total_table[key], alpha, vocab_size)\n",
    "            local p_nospace = laplace_smooth(total_table[key] - space_table[key], total_table[key], alpha, vocab_size)\n",
    "            \n",
    "            --Next char is NOT space\n",
    "            if space_valid[i] == 1 then\n",
    "                perp = perp + math.log(normalize(p_nospace, p_space))\n",
    "            --Next char IS space\n",
    "            else\n",
    "                perp = perp + math.log(normalize(p_space, p_nospace))\n",
    "            end\n",
    "        else\n",
    "            --Probability for unseen counts\n",
    "            perp = perp + math.log(alpha/vocab_size)\n",
    "        end\n",
    "    end\n",
    "    return math.exp(-perp/windows_valid:size(1))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "win_size = X_train:size(2)\n",
    "ngram_space, ngram_total = count_train(X_train, Y_train, win_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COUNT BASED MODEL\t\n",
       "================================\t\n",
       "Window size: 3\t\n",
       "Laplace smoothing parameter: 1\t\n",
       "Perplexity: 1.1981899697832\t\n"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additive = 1\n",
    "perplexity = count_perp(ngram_space, ngram_total, X_valid, Y_valid, win_size, additive, nfeatures)\n",
    "\n",
    "print(\"COUNT BASED MODEL\")\n",
    "print(\"================================\")\n",
    "print(\"Window size: \" .. tostring(win_size))\n",
    "print(\"Laplace smoothing parameter: \" .. tostring(additive))\n",
    "print(\"Perplexity: \" .. tostring(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list=\"\"\n",
    "for i=1,100 do\n",
    "    additive = i/10\n",
    "    perplexity = count_perp(ngram_space, ngram_total, X_valid, Y_valid, win_size, additive, nfeatures)\n",
    "    list=list..tostring(perplexity)..\",\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "padding = torch.Tensor(X_valid_nospaces:size(1), win_size-1):fill(30)\n",
    "padding = padding:type('torch.LongTensor')\n",
    "X_valid_nospaces = torch.cat(padding, X_valid_nospaces, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2 14 15 14 15 18 30 15 18 20 18 20 12 20 12 4 12 4 19 4 19 18 30 19 18 12 18 12 1 12 1 24 30 1 24 22 24 22 1 22 1 15 1 15 21 15 21 21 21 21 14 21 14 12 14 12 14 12 14 23 14 23 4 23 4 21 4 21 9 21 9 4 30 9 4 8 4 8 19 30 8 19 21 19 21 4 21 4 13 4 13 4 13 4 17 4 17 9 17 9 14 9 14 15 14 15 4 30 15 4 18 4 18 1 18 1 13 1 13 8 13 8 21 8 21 21 21 21 13 21 13 4 30 13 4 2 4 2 13 2 13 14 13 14 18 14 18 4 30 18 4 19 4 19 21 19 21 14 30 21 14 21 14 21 9 21 9 4 30 9 4 21 4 21 23 21 23 18 23 18 4 18 4 21 \t\n"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function createHash2(longTensor) \n",
    "    local s = \"\"\n",
    "    for i=1,longTensor:size(2) do\n",
    "        s = s .. tostring(longTensor[1][i]) .. \" \"\n",
    "    end\n",
    "    return s\n",
    "end\n",
    "vocab_size = nfeatures\n",
    "for i=1,X_valid_nospaces:size(1) do\n",
    "    local sen = \"\"\n",
    "    \n",
    "    local flag = true\n",
    "    local idx = 1\n",
    "    \n",
    "    local win = X_valid_nospaces:sub(i,i,idx+win_size-1,idx+win_size-1)\n",
    "    \n",
    "    while flag do\n",
    "        local key = createHash2(win)\n",
    "        sen = sen .. key\n",
    "        if ngram_total[key] then\n",
    "            local p_space = laplace_smooth(ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_nospace = laplace_smooth(ngram_total[key] - ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            p_space = (normalize(p_space, p_nospace))\n",
    "            if p_space > 0.5 then\n",
    "                win = X_valid_nospaces:sub(i,i,idx+1+)\n",
    "            else\n",
    "                idx = idx + 1\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    end\n",
    "    \n",
    "    for j=1,X_valid_nospaces:size(2) do\n",
    "        if X_valid_nospaces:sub(i,i,j+win_size-1,j+win_size-1)[1][1] == 30 then\n",
    "            break\n",
    "        end\n",
    "        local win = X_valid_nospaces:sub(i,i,j,j+win_size-1)\n",
    "        local key = createHash2(win)\n",
    "        --print(key)\n",
    "        sen = sen .. key\n",
    "        if ngram_total[key] then\n",
    "            local p_space = laplace_smooth(ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            local p_nospace = laplace_smooth(ngram_total[key] - ngram_space[key], ngram_total[key], 1, vocab_size)\n",
    "            p_space = (normalize(p_space, p_nospace))\n",
    "            if p_space > 0.5 then\n",
    "                sen = sen .. \"30 \"\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    print(sen)\n",
    "    break\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nil\t\n"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
