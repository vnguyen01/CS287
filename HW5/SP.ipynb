{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require \"hdf5\"\n",
    "require \"optim\"\n",
    "require \"nn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "/Users/Vincent/.luarocks/share/lua/5.1/hdf5/group.lua:312: HDF5Group:read() - no such child 'X_train_sen' for [HDF5Group 33554434 /]\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/Vincent/.luarocks/share/lua/5.1/hdf5/group.lua:312: in function 'read'\n\t[string \"f = hdf5.open(\"data.hdf5\", \"r\")...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/Vincent/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105f33bd0",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "/Users/Vincent/.luarocks/share/lua/5.1/hdf5/group.lua:312: HDF5Group:read() - no such child 'X_train_sen' for [HDF5Group 33554434 /]\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/Vincent/.luarocks/share/lua/5.1/hdf5/group.lua:312: in function 'read'\n\t[string \"f = hdf5.open(\"data.hdf5\", \"r\")...\"]:15: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:179: in function </Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:143>\n\t/Users/Vincent/torch/install/share/lua/5.1/lzmq/poller.lua:75: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t...s/Vincent/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/Vincent/torch/install/share/lua/5.1/itorch/main.lua:350: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105f33bd0"
     ]
    }
   ],
   "source": [
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "\n",
    "X_train = f:read(\"X_train\"):all()\n",
    "Y_train = f:read(\"Y_train\"):all()\n",
    "X_valid = f:read(\"X_valid\"):all()\n",
    "Y_valid = f:read(\"Y_valid\"):all()\n",
    "X_test = f:read(\"X_test\"):all()\n",
    "nwords = f:read(\"nwords\"):all()[1]\n",
    "nclasses = f:read(\"nclasses\"):all()[1]\n",
    "\n",
    "\n",
    "--sentences\n",
    "X_valid_sen = f:read(\"X_valid_sen\"):all()\n",
    "X_test_sen = f:read(\"X_test_sen\"):all()\n",
    "X_train_sen = f:read(\"X_train_sen\"):all()\n",
    "--MEMM\n",
    "X_train_MEMM = f:read(\"X_train_MEMM\"):all()\n",
    "X_valid_MEMM = f:read(\"X_valid_MEMM\"):all()\n",
    "X_valid_sen_MEMM = f:read(\"X_valid_sen_MEMM\"):all()\n",
    "nfeaturesMEMM = f:read(\"nfeaturesMEMM\"):all()[1]\n",
    "\n",
    "C = nclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function process(inputs, numwords)\n",
    "    processed = inputs:clone()\n",
    "    for i = 1, inputs:size(1) do\n",
    "        processed[i][2] = inputs[i][2] + numwords\n",
    "    end\n",
    "    return processed\n",
    "end\n",
    "\n",
    "for i = 1,X_valid_sen_MEMM:size(1) do\n",
    "    X_valid_sen_MEMM[i] = process(X_valid_sen_MEMM[i], nwords)\n",
    "end\n",
    "\n",
    "Y_valid_sen = format_valid(Y_valid, X_valid_sen)\n",
    "y = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "addB = nn.Add(nclasses)\n",
    "lookup = nn.LookupTable(nwords+nclasses,nclasses)\n",
    "sum = nn.Sum(2)\n",
    "tanh = nn.Tanh()\n",
    "linear = nn.Linear(nclasses, nclasses)\n",
    "softmax = nn.LogSoftMax()\n",
    "h = nn.Sequential()\n",
    "h:add(lookup)\n",
    "h:add(sum)\n",
    "h:add(addB)\n",
    "\n",
    "\n",
    "w, dl_dw = h:getParameters()\n",
    "w:zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function gen_score(curr_class, prev_class, input, nword)\n",
    "    local input1 = input[1]\n",
    "    local pair = torch.Tensor{{input1, prev_class+nword}}\n",
    "    local answer = (h:forward(pair))\n",
    "    --answer = nn.LogSoftMax():forward(answer)\n",
    "    return answer[1][curr_class]\n",
    "end\n",
    "\n",
    "function viterbi_gen(sequence, scoring_function, nclass, nword)\n",
    "    local P_table = torch.ones(nclass, sequence:size(1)):mul(-1e10)\n",
    "    local BP = torch.zeros(nclass, sequence:size(1))\n",
    "    local initial = torch.ones(nclass,1) :mul(-1e10)\n",
    "    initial[8] = 1\n",
    "    P_table[{{},{1,1}}] = initial\n",
    "    \n",
    "    local max_ind = 0\n",
    "    local max_prob = -1e10\n",
    "    for i = 2,sequence:size(1) do\n",
    "        for curr_class_ind = 1,nclass do\n",
    "            for prev_class_ind = 1,nclass do\n",
    "                local best_available_P = P_table[curr_class_ind][i]\n",
    "                local candidate_P = scoring_function(curr_class_ind, prev_class_ind, sequence[i], nword)\n",
    "                if candidate_P + P_table[prev_class_ind][i-1] > best_available_P then\n",
    "                    P_table[curr_class_ind][i] = candidate_P + P_table[prev_class_ind][i-1]\n",
    "                    BP[curr_class_ind][i] = prev_class_ind\n",
    "                    if P_table[curr_class_ind][i] > max_prob then\n",
    "                        max_prob = P_table[curr_class_ind][i]\n",
    "                        max_ind = curr_class_ind\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    local classes = torch.zeros(sequence:size(1))\n",
    "    classes[sequence:size(1)] = max_ind\n",
    "    for i = sequence:size(1), 2, -1 do\n",
    "        classes[i-1] = BP[classes[i]][i]\n",
    "    end\n",
    "    return classes\n",
    "end\n",
    "\n",
    "function format_valid(valid, valid_sen)\n",
    "    local y_tags = torch.zeros(valid_sen:size(1), valid_sen:size(2))\n",
    "    local sen_idx = 0\n",
    "    local col_idx = 0\n",
    "    for i=1,valid:size(1) do\n",
    "        if valid[i] == 8 then\n",
    "            sen_idx = sen_idx + 1\n",
    "            col_idx = 1\n",
    "        end\n",
    "        y_tags[sen_idx][col_idx] = valid[i]\n",
    "        col_idx = col_idx + 1\n",
    "    end\n",
    "    return y_tags\n",
    "end\n",
    "\n",
    "function compare(preds, targets)\n",
    "    \n",
    "    local indices = torch.zeros(preds:size(1))\n",
    "    local int = 0\n",
    "    for i = 1, preds:size(1) do\n",
    "        if preds[i] ~= targets[i] then\n",
    "            int = int + 1\n",
    "            indices[int] = i\n",
    "        end\n",
    "    end\n",
    "    if int == 0 then\n",
    "        return 1\n",
    "    end\n",
    "    return indices:sub(1,int)\n",
    "end\n",
    "        \n",
    "function update(sequence, preds, targets, nclass, nword, eta)\n",
    "    \n",
    "    local indexes = compare(preds,targets)\n",
    "    \n",
    "    if indexes == 1 then\n",
    "        return\n",
    "    end\n",
    "    for i = 1,indexes:size(1) do\n",
    "        local index = indexes[i]\n",
    "        if index == 1 then\n",
    "           \n",
    "            input = torch.Tensor{{sequence[index][1], 9+nword}}\n",
    "        else\n",
    "          \n",
    "            input = torch.Tensor{{sequence[index][1], targets[index-1]+nword}}\n",
    "        end\n",
    "        \n",
    "        local prediction = h:forward(input):t()\n",
    "        \n",
    "        \n",
    "        local out_grad = torch.zeros(nclass)\n",
    "        out_grad[preds[index]]= 1/(prediction[preds[index]])[1]\n",
    "        out_grad[targets[index]] = -1/(prediction[targets[index]])[1]\n",
    "       \n",
    "        h:zeroGradParameters()\n",
    "        h:backward(input[1], out_grad)\n",
    "        h:updateParameters(eta)\n",
    "    end\n",
    "end\n",
    "\n",
    "function train_sen(sequence, target, nclass, nword, eta)\n",
    "    local preds = viterbi_gen(sequence, gen_score, nclass, nword)\n",
    "    update(sequence, preds, target, nclass, nword, eta)\n",
    "   \n",
    "    --print(preds)\n",
    "    --print(targets)\n",
    "    --print(compare(preds,targets):size(1))\n",
    "    z = compare(preds,target)\n",
    "    if z == 1 then\n",
    "        return 0\n",
    "    end\n",
    "    return z:size(1)\n",
    "end\n",
    "\n",
    "function train_corp(data, targs, nclass,nword,eta,nepochs)\n",
    "    for j = 1,nepochs do\n",
    "        idx = torch.randperm(data:size(1))\n",
    "        \n",
    "        for k = 1,data:size(1) do\n",
    "            i = idx[k]\n",
    "            local sen = data[i]:sub(1,torch.nonzero(data[{{i,i},{},{1,1}}]):size(1))\n",
    "            local length = train_sen(sen, targs[i]:sub(1,sen:size(1)), nclass, nword, eta)\n",
    "            \n",
    "            if k % 100 == 0 then\n",
    "                print(k,length/sen:size(1))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train_sen = format_valid(Y_train, X_train_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100\t0.38461538461538\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "200\t0.5\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "300\t0.33333333333333\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "400\t0.12903225806452\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "500\t0.090909090909091\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "600\t0.11111111111111\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "700\t0.23529411764706\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "800\t0\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "900\t0.16666666666667\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1000\t0.03030303030303\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1100\t0.12\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1200\t0.66666666666667\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1300\t0.22222222222222\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1400\t0.4375\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1500\t0.9\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1600\t0.5\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1700\t0.11764705882353\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1800\t0.33333333333333\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1900\t0\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2000\t0.5\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2100\t0.5\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2200\t"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2300\t0.4\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2400\t0.44444444444444\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2500\t0.33333333333333\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2600\t0.78260869565217\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2700\t0.77777777777778\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2800\t0.2\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2900\t0.033333333333333\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3000\t0.15\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3100\t0.068965517241379\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3200\t0.35294117647059\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3300\t0.33333333333333\t\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--RUN THIS TO TRAIN, ONE EPOCH TAKES 10 MIN\n",
    "train_corp(X_train_sen, Y_train_sen, nclasses, nwords, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 26\n",
       " 8  5  5  5  5  5  5  5  5  5  5  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 8  3  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 8  3  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 8  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
       "\n",
       "Columns 27 to 52\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 53 to 63\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 10x63]\n",
       "\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function predict_tags(X)\n",
    "    local predictions = torch.zeros(X:size(1), X:size(2))\n",
    "\n",
    "    for i=1,X:size(1) do\n",
    "        local sen = (X[i]:sub(1,torch.nonzero(X[{{i,i},{},{1,1}}]):size(1)))\n",
    "        \n",
    "        \n",
    "        local p = viterbi_gen(sen, gen_score, C, nwords)\n",
    "       \n",
    "        predictions[{{i,i},{1,p:size(1)}}] = p\n",
    "    end\n",
    "    return predictions\n",
    "end\n",
    "\n",
    "function predict_fscore(p_tags, y_tags)\n",
    "    local rel_retrived = {[1]=0,[2]=0,[3]=0,[4]=0,[5]=0}--,[6]=0,[7]=0}\n",
    "    local rel_notretrived = {[1]=0,[2]=0,[3]=0,[4]=0,[5]=0}--,[6]=0,[7]=0}\n",
    "    local irrel_retrived = {[1]=0,[2]=0,[3]=0,[4]=0,[5]=0}--,[6]=0,[7]=0}\n",
    "    for i=1,p_tags:size(1) do\n",
    "        for j=1,p_tags:size(2) do\n",
    "            for tag=1,5 do        \n",
    "                if y_tags[i][j] == tag then\n",
    "                    rel_notretrived[tag] = rel_notretrived[tag] + 1\n",
    "                    if p_tags[i][j] == tag then\n",
    "                        rel_retrived[tag] = rel_retrived[tag] + 1\n",
    "                    else\n",
    "                        irrel_retrived[tag] = irrel_retrived[tag] + 1\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    local recall = 0\n",
    "    local precis = 0\n",
    "    for i=1,5 do\n",
    "        local r = (rel_retrived[i]/(rel_retrived[i]+rel_notretrived[i]))\n",
    "        local p = (rel_retrived[i]/(rel_retrived[i]+irrel_retrived[i]))\n",
    "        --print(i, p, r, 2*p*r/(p+r))\n",
    "        recall = recall + r\n",
    "        precis = precis + p\n",
    "    end\n",
    "    return recall/5,precis/5\n",
    "end\n",
    "\n",
    "-- Writes to file in Kaggle prediction format\n",
    "-- p : prediction tensor\n",
    "-- fname : output filename\n",
    "\n",
    "function kaggle_format(p, fname)\n",
    "    local f = io.open(\"predictions/\" .. fname, \"w\")\n",
    "    f:write(\"ID,Labels\\n\")\n",
    "    for i=1,p:size(1) do\n",
    "        local s = \"\"\n",
    "        local t = {[1]=\"O\",[2]=\"PER\",[3]=\"LOC\",[4]=\"ORG\",[5]=\"MISC\",[6]=\"MISC\",[7]=\"LOC\",[8]=\"O\",[9]=\"O\"}\n",
    "        local prev_tag = 0\n",
    "        local prev_idx = 0\n",
    "        for j=2,p:size(2) do\n",
    "            if p[i][j] == 0 then\n",
    "                break\n",
    "            end\n",
    "            if p[i][j] ~= 1 then\n",
    "                if prev_tag == 0 then\n",
    "                    s = s .. t[p[i][j]] .. \"-\" .. tostring(j-1)\n",
    "                elseif p[i][j] == prev_tag and prev_idx == j-1 then\n",
    "                    s = s .. \"-\" .. tostring(j-1) \n",
    "                else\n",
    "                    s = s .. \" \" .. t[p[i][j]] .. \"-\" .. tostring(j-1)\n",
    "                end\n",
    "                prev_tag = p[i][j]\n",
    "                prev_idx = j\n",
    "            end\n",
    "        end\n",
    "        f:write(i .. \",\" .. s .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--TAKES A FEW MINUTES TO RUN\n",
    "preds = predict_tags(X_test_sen)\n",
    "kaggle_format(preds, \"pred_\" .. tostring(os.time()) .. \"_memm1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1474029143821\t0.24554232441313\t\n",
       "0.18421729365456\t\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "--TAKES A FEW MINUTES TO RUN\n",
    "preds = predict_tags(X_valid_sen)\n",
    "r, p = predict_fscore(preds, Y_valid_sen)\n",
    "print(r, p)\n",
    "print(2*r*p/(r+p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
