{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial = torch.Tensor({\n",
    "{1.0},\n",
    "{0.0},\n",
    "{0.0},\n",
    "}):log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transition = torch.Tensor({\n",
    "{0.0, 0.0, 0.0},\n",
    "{0.8, 0.4, 0.6},\n",
    "{0.2, 0.6, 0.4}\n",
    "}):log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emission = torch.Tensor({\n",
    "-- START, deal, fail, talks\n",
    "{1.0, 0.0, 0.0},\n",
    "{0.0, 0.45, 0.4},\n",
    "{0.0, 0.1, 0.4},\n",
    "{0.0, 0.45, 0.1}\n",
    "}):log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3\n",
       " 3\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 4\n",
       " 3\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(transition:size())\n",
    "print(emission:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- log-scores of transition and emission\n",
    "-- corresponds to the vector y in the lecture notes\n",
    "-- i: timestep for the computed score\n",
    "function score_hmm(observations, i)\n",
    "    print(emission[observations[i]])\n",
    "    print(emission[observations[i]]:view(C, 1))\n",
    "    local observation_emission = emission[observations[i]]:view(C, 1):expand(C, C)\n",
    "    -- NOTE: allocates a new Tensor\n",
    "    return observation_emission + transition\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- Viterbi algorithm.\n",
    "-- observations: a sequence of observations, represented as integers\n",
    "-- logscore: the edge scoring function over classes and observations in a history-based model\n",
    "function viterbi(observations, logscore)\n",
    "    local n = observations:size(1)\n",
    "    local max_table = torch.Tensor(n, C)\n",
    "    local backpointer_table = torch.Tensor(n, C)\n",
    "    \n",
    "    -- first timestep\n",
    "    -- the initial most likely paths are the initial state distribution\n",
    "    -- NOTE: another unnecessary Tensor allocation here\n",
    "    local maxes, backpointers = (initial + emission[observations[1]]):max(2)\n",
    "    max_table[1] = maxes\n",
    "    \n",
    "    -- remaining timesteps (\"forwarding\" the maxes)\n",
    "    for i=2,n do\n",
    "        -- precompute edge scores\n",
    "        y = logscore(observations, i)\n",
    "        scores = y + maxes:view(1, C):expand(C, C)\n",
    "        -- compute new maxes (NOTE: another unnecessary Tensor allocation here)\n",
    "        maxes, backpointers = scores:max(2)\n",
    "        -- record\n",
    "        max_table[i] = maxes\n",
    "        backpointer_table[i] = backpointers\n",
    "    end\n",
    "    -- follow backpointers to recover max path\n",
    "    local classes = torch.Tensor(n)\n",
    "    maxes, classes[n] = maxes:max(1)\n",
    "    for i=n,2,-1 do\n",
    "        classes[i-1] = backpointer_table[{i, classes[i]}]\n",
    "    end\n",
    "    return classes\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        -inf\n",
       " -7.9851e-01\n",
       " -9.1629e-01\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n",
       "        -inf\n",
       " -7.9851e-01\n",
       " -9.1629e-01\n",
       "[torch.DoubleTensor of size 3x1]\n",
       "\n",
       "        -inf         -inf         -inf\n",
       " -1.0217e+00  -1.7148e+00  -1.3093e+00\n",
       " -2.5257e+00  -1.4271e+00  -1.8326e+00\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n",
       "        -inf\n",
       " -7.9851e-01\n",
       " -2.3026e+00\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n",
       "        -inf\n",
       " -7.9851e-01\n",
       " -2.3026e+00\n",
       "[torch.DoubleTensor of size 3x1]\n",
       "\n",
       "        -inf         -inf         -inf\n",
       " -1.0217e+00  -1.7148e+00  -1.3093e+00\n",
       " -3.9120e+00  -2.8134e+00  -3.2189e+00\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n",
       "        -inf\n",
       " -2.3026e+00\n",
       " -9.1629e-01\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n",
       "        -inf\n",
       " -2.3026e+00\n",
       " -9.1629e-01\n",
       "[torch.DoubleTensor of size 3x1]\n",
       "\n",
       "        -inf         -inf         -inf\n",
       " -2.5257e+00  -3.2189e+00  -2.8134e+00\n",
       " -2.5257e+00  -1.4271e+00  -1.8326e+00\n",
       "[torch.DoubleTensor of size 3x3]\n",
       "\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = viterbi(torch.Tensor({1, 2, 4, 3}), score_hmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
