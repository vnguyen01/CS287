{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require('nn')\n",
    "require('hdf5')\n",
    "require('optim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "X_valid = f:read(\"valid_input\"):all()\n",
    "q_valid = f:read(\"valid_q\"):all()\n",
    "X_test = f:read(\"test_input\"):all()\n",
    "q_test = f:read(\"test_q\"):all()\n",
    "kaggle_valid = f:read(\"valid_kaggle\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "f:close()\n",
    "\n",
    "sentences = 42068\n",
    "\n",
    "window_size = X_train:size(2)\n",
    "n_actual = nfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function bigramCount(X, K)\n",
    "    local countMatrix = torch.zeros(K, K)\n",
    "    for i=1,X:size(1) do\n",
    "        for j=2,X:size(2) do\n",
    "            local prev_word = X[i][j-1]\n",
    "            local curr_word = X[i][j]\n",
    "            countMatrix[prev_word][curr_word] = countMatrix[prev_word][curr_word] + 1\n",
    "        end\n",
    "    end\n",
    "    return countMatrix\n",
    "end\n",
    "\n",
    "function unigramCount(X, Y, K)\n",
    "    local countVector = torch.zeros(1, K)\n",
    "    for i=1,X:size(1) do\n",
    "        for j=2,X:size(2) do\n",
    "            local idx = X[i][j]\n",
    "            countVector[1][idx] = countVector[1][idx] + 1\n",
    "        end\n",
    "    end\n",
    "    return countVector\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function additive(matrix, alpha)\n",
    "    local add_matrix = matrix:add(alpha)\n",
    "    return add_matrix\n",
    "end\n",
    "\n",
    "function normalize(CV, CM)\n",
    "    --divide by counts of previous word\n",
    "    local norm = torch.cdiv(CM,torch.expand(CV:t(), CM:size(1), CM:size(2)))\n",
    "    return norm\n",
    "end\n",
    "\n",
    "function bigramPerp(bcm, X, correct, q_50)\n",
    "    p = 0\n",
    "    for i=1,X:size(1) do\n",
    "        idx = q_50[i][correct[i]]\n",
    "        prev_word = X[i][5]\n",
    "        p = torch.log(bcm[prev_word][idx]) + p\n",
    "    end\n",
    "    return torch.exp(-p/X_valid:size(1))\n",
    "end\n",
    "\n",
    "function kaggle(bcm, test, q)\n",
    "    scores = torch.zeros(q:size(1), 50)\n",
    "    for i=1,test:size(1) do\n",
    "        prev = test[i][5]\n",
    "        for j=1,50 do\n",
    "            w = q[i][j]\n",
    "            scores[i][j] = bcm[prev][w]\n",
    "        end\n",
    "    end\n",
    "    return scores:cdiv(torch.expand((torch.sum(scores, 2)), scores:size(1), scores:size(2)))\n",
    "end\n",
    "\n",
    "function write2file(scores, fname)\n",
    "    f = io.open(fname, \"w\")\n",
    "    f:write(\"ID,Class1,CLass2,Class3,Class4,Class5,Class6,Class7,Class8,Class9,Class10,Class11,Class12,CLass13,Class14,Class15,Class16,Class17,Class18,Class19,Class20,Class21,Class22,Class23,CLass24,Class25,Class26,Class27,Class28,Class29,Class30,Class31,Class32,Class33,Class34,CLass35,Class36,Class37,Class38,Class39,Class40,Class41,Class42,Class43,Class44,Class45,CLass46,Class47,Class48,Class49,Class50\\n\")\n",
    "    for i=1,scores:size(1) do\n",
    "        s = tostring(i)\n",
    "        for j=1, scores:size(2) do\n",
    "            s = s .. \",\" .. tostring(scores[i][j])\n",
    "        end\n",
    "        f:write(s .. \"\\n\")\n",
    "    end\n",
    "    f:close()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CM = bigramCount(X_train, nfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CV = unigramCount(X_train, Y_train, nfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BCM = normalize(CV, CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = kaggle(BCM, X_test, q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write2file(scores, \"asdf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1268.7793631882\t\n"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigramPerp(bcm, X_valid, kaggle_valid, q_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bcm = torch.cdiv(BCM, torch.expand(BCM:sum(2), BCM:size(1), BCM:size(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999999999975\t\n"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcm:sub(1,1):sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     3      3      3   9981  10001\n",
       "     3      3   9981  10001   9987\n",
       "     3   9981  10001   9987   9978\n",
       "  9981  10001   9987   9978   9991\n",
       " 10001   9987   9978   9991   9975\n",
       "  9987   9978   9991   9975   9985\n",
       "  9978   9991   9975   9985   9977\n",
       "  9991   9975   9985   9977   9993\n",
       "  9975   9985   9977   9993   9972\n",
       "  9985   9977   9993   9972   9973\n",
       "  9977   9993   9972   9973   9989\n",
       "  9993   9972   9973   9989   9997\n",
       "  9972   9973   9989   9997   9979\n",
       "  9973   9989   9997   9979   9983\n",
       "  9989   9997   9979   9983   9974\n",
       "  9997   9979   9983   9974   9984\n",
       "  9979   9983   9974   9984   9990\n",
       "  9983   9974   9984   9990   9976\n",
       "  9974   9984   9990   9976  10000\n",
       "  9984   9990   9976  10000   9994\n",
       "  9990   9976  10000   9994   9995\n",
       "  9976  10000   9994   9995   9998\n",
       " 10000   9994   9995   9998   9986\n",
       "     3      3      3   9000      2\n",
       "     3      3   9000      2      5\n",
       "     3   9000      2      5     74\n",
       "  9000      2      5     74    395\n",
       "     2      5     74    395     35\n",
       "     5     74    395     35   2150\n",
       "    74    395     35   2150      1\n",
       "   395     35   2150      1    148\n",
       "    35   2150      1    148     21\n",
       "  2150      1    148     21      8\n",
       "     1    148     21      8   9477\n",
       "   148     21      8   9477    277\n",
       "    21      8   9477    277    409\n",
       "     8   9477    277    409      5\n",
       "     3      3      3     25      2\n",
       "     3      3     25      2     15\n",
       "     3     25      2     15    144\n",
       "    25      2     15    144      6\n",
       "     2     15    144      6      2\n",
       "    15    144      6      2   5461\n",
       "   144      6      2   5461      1\n",
       "     6      2   5461      1   3108\n",
       "     2   5461      1   3108   1585\n",
       "  5461      1   3108   1585     98\n",
       "     3      3      3   7254      2\n",
       "     3      3   7254      2      5\n",
       "     3   7254      2      5     74\n",
       "[torch.LongTensor of size 50x5]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train:sub(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_sen_idx = torch.zeros(1, 41931)\n",
    "sen_count = 0\n",
    "for i=1,X_train:size(1) do\n",
    "    row = X_train[i]\n",
    "    if (row[1] ==row[2] and row[2]==row[3] and row[1]==3) then\n",
    "        sen_count = sen_count + 1\n",
    "        new_sen_idx[1][sen_count] = i \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     3\n",
       "     3\n",
       "     3\n",
       "  9981\n",
       " 10001\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       " 9987\n",
       " 9978\n",
       " 9991\n",
       " 9975\n",
       " 9985\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       " 9977\n",
       " 9993\n",
       " 9972\n",
       " 9973\n",
       " 9989\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       " 9997\n",
       " 9979\n",
       " 9983\n",
       " 9974\n",
       " 9984\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "  9990\n",
       "  9976\n",
       " 10000\n",
       "  9994\n",
       "  9995\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "21\t\n",
       "3\t\n",
       " 10000\n",
       "  9994\n",
       "  9995\n",
       "  9998\n",
       "  9986\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "    3\n",
       "    3\n",
       "    3\n",
       " 9000\n",
       "    2\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "    5\n",
       "   74\n",
       "  395\n",
       "   35\n",
       " 2150\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "    1\n",
       "  148\n",
       "   21\n",
       "    8\n",
       " 9477\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "34\t\n",
       "17\t\n",
       "    8\n",
       " 9477\n",
       "  277\n",
       "  409\n",
       "    5\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "  3\n",
       "  3\n",
       "  3\n",
       " 25\n",
       "  2\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "   15\n",
       "  144\n",
       "    6\n",
       "    2\n",
       " 5461\n",
       "[torch.LongTensor of size 5]\n",
       "\n",
       "    3\n",
       "    3\n",
       "    3\n",
       " 7254\n",
       "    2\n",
       "[torch.LongTensor of size 5]\n",
       "\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_counter = 2\n",
    "i = 1\n",
    "while i < 50 do\n",
    "    if i <= new_sen_idx[1][sen_counter] then\n",
    "        print(test[i])\n",
    "        i = i + 5\n",
    "    else\n",
    "        last_win = new_sen_idx[1][sen_counter]-1\n",
    "        print(i-5)\n",
    "        print(new_sen_idx[1][sen_counter]-21)\n",
    "        print(test[last_win])\n",
    "        i = new_sen_idx[1][sen_counter]\n",
    "        sen_counter = sen_counter + 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = X_train:sub(1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     3      3      3   9981  10001\n",
       "     3      3   9981  10001   9987\n",
       "     3   9981  10001   9987   9978\n",
       "  9981  10001   9987   9978   9991\n",
       " 10001   9987   9978   9991   9975\n",
       "  9987   9978   9991   9975   9985\n",
       "  9978   9991   9975   9985   9977\n",
       "  9991   9975   9985   9977   9993\n",
       "  9975   9985   9977   9993   9972\n",
       "  9985   9977   9993   9972   9973\n",
       "  9977   9993   9972   9973   9989\n",
       "  9993   9972   9973   9989   9997\n",
       "  9972   9973   9989   9997   9979\n",
       "  9973   9989   9997   9979   9983\n",
       "  9989   9997   9979   9983   9974\n",
       "  9997   9979   9983   9974   9984\n",
       "  9979   9983   9974   9984   9990\n",
       "  9983   9974   9984   9990   9976\n",
       "  9974   9984   9990   9976  10000\n",
       "  9984   9990   9976  10000   9994\n",
       "  9990   9976  10000   9994   9995\n",
       "  9976  10000   9994   9995   9998\n",
       " 10000   9994   9995   9998   9986\n",
       "     3      3      3   9000      2\n",
       "     3      3   9000      2      5\n",
       "     3   9000      2      5     74\n",
       "  9000      2      5     74    395\n",
       "     2      5     74    395     35\n",
       "     5     74    395     35   2150\n",
       "    74    395     35   2150      1\n",
       "   395     35   2150      1    148\n",
       "    35   2150      1    148     21\n",
       "  2150      1    148     21      8\n",
       "     1    148     21      8   9477\n",
       "   148     21      8   9477    277\n",
       "    21      8   9477    277    409\n",
       "     8   9477    277    409      5\n",
       "     3      3      3     25      2\n",
       "     3      3     25      2     15\n",
       "     3     25      2     15    144\n",
       "    25      2     15    144      6\n",
       "     2     15    144      6      2\n",
       "    15    144      6      2   5461\n",
       "   144      6      2   5461      1\n",
       "     6      2   5461      1   3108\n",
       "     2   5461      1   3108   1585\n",
       "  5461      1   3108   1585     98\n",
       "     3      3      3   7254      2\n",
       "     3      3   7254      2      5\n",
       "     3   7254      2      5     74\n",
       "[torch.LongTensor of size 50x5]\n",
       "\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
