{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('nn')\n",
    "require('hdf5')\n",
    "require('optim')\n",
    "\n",
    "f = hdf5.open(\"data.hdf5\", \"r\")\n",
    "X_train = f:read(\"train_input\"):all()\n",
    "Y_train = f:read(\"train_output\"):all()\n",
    "X_valid = f:read(\"valid_input\"):all()\n",
    "q_valid = f:read(\"valid_q\"):all()\n",
    "X_test = f:read(\"test_input\"):all()\n",
    "q_test = f:read(\"test_q\"):all()\n",
    "kaggle_valid = f:read(\"valid_kaggle\"):all()\n",
    "nclasses = f:read('nclasses'):all():long()[1]\n",
    "nfeatures = f:read('nfeatures'):all():long()[1]\n",
    "n_reduced = 1001\n",
    "f:close()\n",
    "\n",
    "window_size = X_train:size(2)\n",
    "n_actual = nfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "embedded_size = 100\n",
    "D_h = 100\n",
    "\n",
    "lookup1 = nn.LookupTable(nfeatures,embedded_size)\n",
    "linear1 = nn.Linear(window_size*embedded_size, D_h)\n",
    "tanh = nn.HardTanh()\n",
    "linear2 = nn.Linear(D_h, n_actual)\n",
    "h = nn.Sequential()\n",
    "h:add(lookup1)\n",
    "h:add(nn.Reshape(window_size*embedded_size, True))\n",
    "h:add(linear1)\n",
    "h:add(tanh)\n",
    "h:add(linear2)\n",
    "\n",
    "mse = nn.CrossEntropyCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss for iteration 10 is 5.3462612690193\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 20 is 6.8115822413589\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 30 is 6.1787073569588\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 40 is 5.3995086481801\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 50 is 5.4829083572653\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 60 is 4.9841508303582\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 70 is 6.0303520975489\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 80 is 6.0063622168267\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 90 is 6.3071935072453\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "loss for iteration 100 is 4.4564815836598\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, dl_dw = h:getParameters()\n",
    "\n",
    "\n",
    "feval = function(w_new)\n",
    "   \n",
    "    bsize= batch\n",
    "    local idx = torch.randperm(X_train:size(1)):sub(1,bsize)\n",
    "\n",
    "    x = torch.Tensor(bsize, X_train:size(2))\n",
    "\n",
    "    \n",
    "    --y = y:reshape(Y_train:size(1), 1)\n",
    "    \n",
    "    y_ = torch.Tensor(bsize, 1)\n",
    "\n",
    "    for i=1,bsize do\n",
    "        x[i] = X_train[idx[i]]\n",
    "        y_[i] = Y_train[idx[i]]\n",
    "    end\n",
    "    \n",
    "    y_ = y_:squeeze()\n",
    "    \n",
    "    local inputs = x\n",
    "    local targets = y_\n",
    "    -- reset gradients (gradients are always accumulated, to accommodate\n",
    "    -- batch methods)\n",
    "    dl_dw:zero()\n",
    "\n",
    "    -- evaluate the loss function and its derivative with respect to x, given a mini batch\n",
    "    local prediction = h:forward(inputs)\n",
    "    local loss_w = mse:forward(prediction, targets)\n",
    "    h:backward(inputs, mse:backward(prediction, targets))\n",
    "    return loss_w, dl_dw\n",
    "            \n",
    "end\n",
    "\n",
    "batch = 32\n",
    "\n",
    "-- cycle on data\n",
    "for i = 1,100 do\n",
    "    -- train a mini_batch of batchSize in parallel\n",
    "    _, fs = optim.adam(feval,w)\n",
    "\n",
    "    if i % 10 == 0 then\n",
    "        print('loss for iteration ' .. i  .. ' is ' .. fs[1] )\n",
    "        -- print(sgd_params)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function perplexity(input_set, output_set, kaggle)\n",
    "    sum = 0\n",
    "    for i = 1,input_set:size(1) do\n",
    "        a = h:forward(input_set[i])\n",
    "        b = nn.Index(1):forward{a,output_set[i]}\n",
    "        distribution = nn.LogSoftMax():forward(b)\n",
    "        answer = distribution[kaggle[i]]\n",
    "        sum = sum + answer\n",
    "    end\n",
    "\n",
    "    return torch.exp(-sum/input_set:size(1))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.72248283031\t\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
